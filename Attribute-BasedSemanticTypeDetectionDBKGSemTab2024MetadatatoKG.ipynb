{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read FiftyDatasets/AllDatasetsInfo/AllDataSourcesInfo/Kaggle/Sato/ Viznet datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sem\n",
      "Using SemTabTest 2024 terms\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import re  \n",
    "\n",
    "DB_or_dataset = input(\"Insert if using Datasets (d), Database.tables (dt), the two Data Sources (ds), Kaggle Datasets (k), Kaggle Datasets to correct (kc), Sato Datasets (s), Sato Filtered (sf), Filtered Viznet Datasets (v), or Filtered Kaggle Viznet Datasets (kv): \")\n",
    "\n",
    "print(DB_or_dataset)\n",
    "\n",
    "if DB_or_dataset.lower() == 'd':\n",
    "    print(\"Using Datasets\")\n",
    "    datasets_xlsx = pd.read_excel(\"FiftyDatasets.xlsx\") \n",
    "    columns_xlsx = pd.read_excel(\"AllColumnsFromFiftyDatasets.xlsx\")\n",
    "    analysed_columns_file_path = 'AnalysedColumns.xlsx'     \n",
    "elif DB_or_dataset.lower() == 'dt':\n",
    "    print(\"Using Database tables\")\n",
    "    datasets_xlsx = pd.read_excel(\"AllDatasetsInfo.xlsx\")\n",
    "    columns_xlsx = pd.read_excel(\"AllColumnsInfo.xlsx\")\n",
    "    analysed_columns_file_path = 'AnalysedColumnsDB.xlsx'\n",
    "elif DB_or_dataset.lower() == 'ds':\n",
    "    print(\"Using Datasets and Database tables\")\n",
    "    datasets_xlsx = pd.read_excel(\"AllDataSourcesInfo.xlsx\")\n",
    "    columns_xlsx = pd.read_excel(\"AllAttributes_andColumnsInfo.xlsx\")\n",
    "    analysed_columns_file_path = 'AnalysedColumnsDS.xlsx'\n",
    "elif DB_or_dataset.lower() == 'k':\n",
    "    print(\"Using Kaggle Datasets\")\n",
    "    datasets_xlsx = pd.read_excel(\"kaggle_datasets_with_domain_and_match.xlsx\")\n",
    "    columns_xlsx = pd.read_excel(\"kaggle_headers.xlsx\")\n",
    "    analysed_columns_file_path = 'AnalysedColumnsK.xlsx'\n",
    "elif DB_or_dataset.lower() == 'kc':\n",
    "    print(\"Using Kaggle Datasets Corrections\")\n",
    "    datasets_xlsx = pd.read_excel(\"kaggle_datasets_with_domain_and_match.xlsx\")\n",
    "    columns_xlsx = pd.read_excel(\"kaggle_headers_10k.xlsx\")\n",
    "    analysed_columns_file_path = 'AnalysedColumnsKc.xlsx'\n",
    "elif DB_or_dataset.lower() == 's':\n",
    "    print(\"Using Sato Datasets\")\n",
    "    datasets_xlsx = pd.read_excel(\"datasets_viznet.xlsx\")\n",
    "    columns_xlsx = pd.read_excel(\"columns_sato_only.xlsx\")\n",
    "    analysed_columns_file_path = 'AnalysedColumnsSato.xlsx'\n",
    "elif DB_or_dataset.lower() == 'sf':\n",
    "    print(\"Using Sato Filtered Datasets\")\n",
    "    datasets_xlsx = pd.read_excel(\"datasets_viznet.xlsx\")\n",
    "    columns_xlsx = pd.read_excel(\"filtered_columns_sato_only.xlsx\")\n",
    "    analysed_columns_file_path = 'AnalysedColumnsSatoFiltered.xlsx'\n",
    "elif DB_or_dataset.lower() == 'v':\n",
    "    print(\"Using Viznet Filtered Datasets\")\n",
    "    datasets_xlsx = pd.read_excel(\"datasets_viznet.xlsx\")\n",
    "    columns_xlsx = pd.read_excel(\"filtered_columns_viznet_all.xlsx\")\n",
    "    analysed_columns_file_path = 'AnalysedColumnsViznetFiltered.xlsx'\n",
    "elif DB_or_dataset.lower() == 'kv':\n",
    "    print(\"Using Kaggle Viznet Filtered Datasets\")\n",
    "    datasets_xlsx = pd.read_excel(\"kaggle_viznet_datasets.xlsx\")\n",
    "    columns_xlsx = pd.read_excel(\"filtered_kaggle_viznet_headers.xlsx\")\n",
    "    analysed_columns_file_path = 'AnalysedColumnsKaggleViznetFiltered.xlsx'\n",
    "elif DB_or_dataset.lower() == 'sem':\n",
    "    print(\"Using SemTabTest 2024 terms\")\n",
    "    datasets_xlsx = pd.read_excel(\"SemTabTest2024Dataset.xlsx\")\n",
    "    columns_xlsx = pd.read_excel(\"SemTabTest2024.xlsx\")\n",
    "    analysed_columns_file_path = 'AnalysedColumnsSemTabTest2024.xlsx'\n",
    "elif DB_or_dataset.lower() == 'dbp':\n",
    "    print(\"Using DbPedia metadata\")\n",
    "    datasets_xlsx = pd.read_excel(\"DbpediaDataset.xlsx\")\n",
    "    columns_xlsx = pd.read_excel(\"DbpediaMetadataColumns.xlsx\")\n",
    "    analysed_columns_file_path = 'AnalysedColumnsDbpediaMetadata.xlsx'\n",
    "else:\n",
    "    raise ValueError(\"Invalid input. Please enter 'd', 'dt', 'ds', 'k', 'kc', 's', 'sf', 'v' or 'kv'.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset_index</th>\n",
       "      <th>name</th>\n",
       "      <th>area</th>\n",
       "      <th>Original Column</th>\n",
       "      <th>ID</th>\n",
       "      <th>Column</th>\n",
       "      <th>Path_Column</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>r1_test_metadata.jsonl</td>\n",
       "      <td>SemTabTest</td>\n",
       "      <td>SemTab2024</td>\n",
       "      <td>1.  ALT(m)</td>\n",
       "      <td>1</td>\n",
       "      <td>ALT(m)</td>\n",
       "      <td>1146722_1_7558140036342906956_ALT(m)</td>\n",
       "      <td>http://dbpedia.org/ontology/elevation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>r1_test_metadata.jsonl</td>\n",
       "      <td>SemTabTest</td>\n",
       "      <td>SemTab2024</td>\n",
       "      <td>2.  Endroit</td>\n",
       "      <td>2</td>\n",
       "      <td>Endroit</td>\n",
       "      <td>11599512_1_280388135214354946_Endroit</td>\n",
       "      <td>http://dbpedia.org/ontology/region</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>r1_test_metadata.jsonl</td>\n",
       "      <td>SemTabTest</td>\n",
       "      <td>SemTab2024</td>\n",
       "      <td>3.  AUReleaseDate</td>\n",
       "      <td>3</td>\n",
       "      <td>AUReleaseDate</td>\n",
       "      <td>11833461_1_3811022039809817402_AUReleaseDate</td>\n",
       "      <td>http://dbpedia.org/ontology/releaseDate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>r1_test_metadata.jsonl</td>\n",
       "      <td>SemTabTest</td>\n",
       "      <td>SemTab2024</td>\n",
       "      <td>4.  EUReleaseDate</td>\n",
       "      <td>4</td>\n",
       "      <td>EUReleaseDate</td>\n",
       "      <td>11833461_1_3811022039809817402_EUReleaseDate</td>\n",
       "      <td>http://dbpedia.org/ontology/releaseDate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>r1_test_metadata.jsonl</td>\n",
       "      <td>SemTabTest</td>\n",
       "      <td>SemTab2024</td>\n",
       "      <td>5.  Publisher</td>\n",
       "      <td>5</td>\n",
       "      <td>Publisher</td>\n",
       "      <td>11833461_1_3811022039809817402_Publisher</td>\n",
       "      <td>http://dbpedia.org/ontology/publisher</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            dataset_index        name        area    Original Column  ID  \\\n",
       "0  r1_test_metadata.jsonl  SemTabTest  SemTab2024         1.  ALT(m)   1   \n",
       "1  r1_test_metadata.jsonl  SemTabTest  SemTab2024        2.  Endroit   2   \n",
       "2  r1_test_metadata.jsonl  SemTabTest  SemTab2024  3.  AUReleaseDate   3   \n",
       "3  r1_test_metadata.jsonl  SemTabTest  SemTab2024  4.  EUReleaseDate   4   \n",
       "4  r1_test_metadata.jsonl  SemTabTest  SemTab2024      5.  Publisher   5   \n",
       "\n",
       "          Column                                   Path_Column  \\\n",
       "0         ALT(m)          1146722_1_7558140036342906956_ALT(m)   \n",
       "1        Endroit         11599512_1_280388135214354946_Endroit   \n",
       "2  AUReleaseDate  11833461_1_3811022039809817402_AUReleaseDate   \n",
       "3  EUReleaseDate  11833461_1_3811022039809817402_EUReleaseDate   \n",
       "4      Publisher      11833461_1_3811022039809817402_Publisher   \n",
       "\n",
       "                                       URL  \n",
       "0    http://dbpedia.org/ontology/elevation  \n",
       "1       http://dbpedia.org/ontology/region  \n",
       "2  http://dbpedia.org/ontology/releaseDate  \n",
       "3  http://dbpedia.org/ontology/releaseDate  \n",
       "4    http://dbpedia.org/ontology/publisher  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_xlsx = columns_xlsx.rename(columns={'index': 'dataset_index'})\n",
    "\n",
    "columns_xlsx.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last run on: 2025-11-07 21:44:15\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset_index</th>\n",
       "      <th>name</th>\n",
       "      <th>area</th>\n",
       "      <th>Original Column</th>\n",
       "      <th>ID</th>\n",
       "      <th>Column</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SATO_000001</td>\n",
       "      <td>None</td>\n",
       "      <td>Sato-Viznet</td>\n",
       "      <td>14. num (the predicted attribute)</td>\n",
       "      <td>14</td>\n",
       "      <td>num</td>\n",
       "      <td>the predicted attribute</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SATO_000001</td>\n",
       "      <td>None</td>\n",
       "      <td>Sato-Viznet</td>\n",
       "      <td>1. lettr: capital letter (26 values from A to Z)</td>\n",
       "      <td>1</td>\n",
       "      <td>lettr</td>\n",
       "      <td>capital letter  26 values from A to Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SATO_000001</td>\n",
       "      <td>None</td>\n",
       "      <td>Sato-Viznet</td>\n",
       "      <td>2. x-box: horizontal position of the box (inte...</td>\n",
       "      <td>2</td>\n",
       "      <td>x-box</td>\n",
       "      <td>horizontal position of the box  integer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SATO_000001</td>\n",
       "      <td>None</td>\n",
       "      <td>Sato-Viznet</td>\n",
       "      <td>1. sepal length in cm</td>\n",
       "      <td>1</td>\n",
       "      <td>sepal length in cm</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SATO_000001</td>\n",
       "      <td>None</td>\n",
       "      <td>Sato-Viznet</td>\n",
       "      <td>20. Foreign worker (qualitative)</td>\n",
       "      <td>20</td>\n",
       "      <td>Foreign worker</td>\n",
       "      <td>qualitative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SATO_000001</td>\n",
       "      <td>None</td>\n",
       "      <td>Sato-Viznet</td>\n",
       "      <td>12. A12: Categorical with values: t, f</td>\n",
       "      <td>12</td>\n",
       "      <td>A12</td>\n",
       "      <td>Categorical with values: t, f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SATO_000001</td>\n",
       "      <td>None</td>\n",
       "      <td>Sato-Viznet</td>\n",
       "      <td>55. capital_run_length_average (1 continuous r...</td>\n",
       "      <td>55</td>\n",
       "      <td>capital_run_length_average</td>\n",
       "      <td>1 continuous real attribute: Average length of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SATO_000001</td>\n",
       "      <td>None</td>\n",
       "      <td>Sato-Viznet</td>\n",
       "      <td>1. Class Name (party affiliation): democrat, r...</td>\n",
       "      <td>1</td>\n",
       "      <td>Class Name</td>\n",
       "      <td>party affiliation: democrat, republican</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SATO_000001</td>\n",
       "      <td>None</td>\n",
       "      <td>Sato-Viznet</td>\n",
       "      <td>1.Sex / nominal / -- / M, F, and I (infant)</td>\n",
       "      <td>1</td>\n",
       "      <td>Sex</td>\n",
       "      <td>nominal / -- / M, F, and I  infant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SATO_000001</td>\n",
       "      <td>None</td>\n",
       "      <td>Sato-Viznet</td>\n",
       "      <td>3.Cell Nucleus 1 - a) radius (mean of distance...</td>\n",
       "      <td>3</td>\n",
       "      <td>Cell Nucleus 1 - a) radius</td>\n",
       "      <td>mean of distances from center to points on the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SATO_000001</td>\n",
       "      <td>None</td>\n",
       "      <td>Sato-Viznet</td>\n",
       "      <td>14. win_loc (varchar(255))</td>\n",
       "      <td>14</td>\n",
       "      <td>win_loc</td>\n",
       "      <td>varchar 255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SATO_000001</td>\n",
       "      <td>None</td>\n",
       "      <td>Sato-Viznet</td>\n",
       "      <td>2.   Country</td>\n",
       "      <td>2</td>\n",
       "      <td>Country</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dataset_index  name         area  \\\n",
       "0    SATO_000001  None  Sato-Viznet   \n",
       "1    SATO_000001  None  Sato-Viznet   \n",
       "2    SATO_000001  None  Sato-Viznet   \n",
       "3    SATO_000001  None  Sato-Viznet   \n",
       "4    SATO_000001  None  Sato-Viznet   \n",
       "5    SATO_000001  None  Sato-Viznet   \n",
       "6    SATO_000001  None  Sato-Viznet   \n",
       "7    SATO_000001  None  Sato-Viznet   \n",
       "8    SATO_000001  None  Sato-Viznet   \n",
       "9    SATO_000001  None  Sato-Viznet   \n",
       "10   SATO_000001  None  Sato-Viznet   \n",
       "11   SATO_000001  None  Sato-Viznet   \n",
       "\n",
       "                                      Original Column  ID  \\\n",
       "0                   14. num (the predicted attribute)  14   \n",
       "1    1. lettr: capital letter (26 values from A to Z)   1   \n",
       "2   2. x-box: horizontal position of the box (inte...   2   \n",
       "3                               1. sepal length in cm   1   \n",
       "4                    20. Foreign worker (qualitative)  20   \n",
       "5              12. A12: Categorical with values: t, f  12   \n",
       "6   55. capital_run_length_average (1 continuous r...  55   \n",
       "7   1. Class Name (party affiliation): democrat, r...   1   \n",
       "8         1.Sex / nominal / -- / M, F, and I (infant)   1   \n",
       "9   3.Cell Nucleus 1 - a) radius (mean of distance...   3   \n",
       "10                         14. win_loc (varchar(255))  14   \n",
       "11                                       2.   Country   2   \n",
       "\n",
       "                        Column  \\\n",
       "0                          num   \n",
       "1                        lettr   \n",
       "2                        x-box   \n",
       "3           sepal length in cm   \n",
       "4               Foreign worker   \n",
       "5                          A12   \n",
       "6   capital_run_length_average   \n",
       "7                   Class Name   \n",
       "8                          Sex   \n",
       "9   Cell Nucleus 1 - a) radius   \n",
       "10                     win_loc   \n",
       "11                     Country   \n",
       "\n",
       "                                          Description  \n",
       "0                             the predicted attribute  \n",
       "1               capital letter  26 values from A to Z  \n",
       "2             horizontal position of the box  integer  \n",
       "3                                                 NaN  \n",
       "4                                         qualitative  \n",
       "5                       Categorical with values: t, f  \n",
       "6   1 continuous real attribute: Average length of...  \n",
       "7             party affiliation: democrat, republican  \n",
       "8                  nominal / -- / M, F, and I  infant  \n",
       "9   mean of distances from center to points on the...  \n",
       "10                                        varchar 255  \n",
       "11                                                NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "def clean_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    # 1. Extract the ID from the column name \n",
    "    df['ID'] = df['Original Column'].str.extract(r'(\\d+)\\.')\n",
    "\n",
    "    # 2. Extract the Column name up to the first colon, slash, or parenthesis\n",
    "    df['Column'] = df['Original Column'].str.extract(r'\\d+\\.\\s*([^/(:]+)')\n",
    "\n",
    "    # 3. Extract everything after the first colon, slash, or parenthesis as the full description\n",
    "    df['Description'] = df['Original Column'].str.extract(r'\\d+\\.\\s*[^/(:]+\\s*[:(/](.*)')[0]\n",
    "\n",
    "    # 4. For cases where Description is None,\n",
    "    #    extract the content within parentheses\n",
    "    mask = df['Description'].isnull()\n",
    "    df.loc[mask, 'Description'] = df.loc[mask, 'Original Column'].str.extract(r'\\(([^)]+)\\)')\n",
    "\n",
    "    # 5. Trim spaces from all string columns\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == \"object\" and col != 'dataset_index':\n",
    "            df[col] = df[col].str.strip()\n",
    "\n",
    "    # 6. Replace empty strings with pd.NA  ← changed from None to pd.NA to avoid downcasting warning\n",
    "    df = df.replace(r'^\\s*$', pd.NA, regex=True)\n",
    "    df = df.infer_objects(copy=False)\n",
    "    \n",
    "    # 7. Ensure Description is object dtype before applying .str.replace  ← added to avoid incompatible dtype warning\n",
    "    df['Description'] = df['Description'].astype(object)\n",
    "\n",
    "    # 8. Only apply .str.replace on non-null Description rows,\n",
    "    #    converting to string first to avoid errors\n",
    "    mask_desc = df['Description'].notnull()\n",
    "    df.loc[mask_desc, 'Description'] = (\n",
    "        df.loc[mask_desc, 'Description']\n",
    "          .astype(str)\n",
    "          .str.replace(r'\\(', ' ', regex=True)\n",
    "          .str.replace(r'\\)', '', regex=True)\n",
    "    )\n",
    "\n",
    "    # 9. Reorder columns to ensure ID comes before Column\n",
    "    columns_order = ['dataset_index', 'name', 'area', 'Original Column', 'ID', 'Column', 'Description']\n",
    "    columns_order = [col for col in columns_order if col in df.columns]\n",
    "    df = df[columns_order]\n",
    "\n",
    "    return df\n",
    "\n",
    "# Test the function with a sample DataFrame\n",
    "if __name__ == \"__main__\":\n",
    "    test_df = pd.DataFrame({\n",
    "        'Original Column': [\n",
    "            '14. num (the predicted attribute)',\n",
    "            '1. lettr: capital letter (26 values from A to Z)',\n",
    "            '2. x-box: horizontal position of the box (integer)',\n",
    "            '1. sepal length in cm',\n",
    "            '20. Foreign worker (qualitative)',\n",
    "            '12. A12: Categorical with values: t, f',\n",
    "            '55. capital_run_length_average (1 continuous real attribute): Average length of uninterrupted sequences of capital letters',\n",
    "            '1. Class Name (party affiliation): democrat, republican',\n",
    "            '1.Sex / nominal / -- / M, F, and I (infant)',\n",
    "            '3.Cell Nucleus 1 - a) radius (mean of distances from center to points on the perimeter)',\n",
    "            '14. win_loc (varchar(255))',\n",
    "            '2.   Country'\n",
    "        ],\n",
    "        'dataset_index': ['SATO_000001'] * 12,\n",
    "        'name': [None] * 12,\n",
    "        'area': ['Sato-Viznet'] * 12\n",
    "    })\n",
    "\n",
    "print(f\"Last run on: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "cleaned_df = clean_columns(test_df)\n",
    "cleaned_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open formats and abreviations dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last run on: 2025-11-07 21:44:15\n"
     ]
    }
   ],
   "source": [
    "dictionary = {}\n",
    "\n",
    "# Open the formats dictionary file and read line by line \n",
    "with open(\"formats_dictionary.txt\", \"r\") as file:\n",
    "    for line in file:\n",
    "        # Remove the trailing newline and comma, then split the line into key and value at the colon\n",
    "        key, value = line.rstrip(\",\\n\").split(\":\")\n",
    "    \n",
    "        # Remove the quotes around the key and value\n",
    "        key = key.strip(\"'\").lower()\n",
    "        value = value.strip(\"'\")\n",
    "\n",
    "        # Add the key-value pair to the dictionary\n",
    "        dictionary[key] = value\n",
    "\n",
    "# Load the abbreviations dictionary\n",
    "abbreviations_dict = {}\n",
    "with open(\"abbreviations_dictionary.txt\", \"r\") as file:\n",
    "    for line in file:\n",
    "        abbr, full_form = line.strip().split(\":\")\n",
    "        abbreviations_dict[abbr.strip().lower()] = full_form.strip()\n",
    "        \n",
    "print(f\"Last run on: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace abbreviations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Original Column</th>\n",
       "      <th>AbbrExpanded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1. chlorides (mg/dL)</td>\n",
       "      <td>1 chlorides mg dL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2. chloride (mg/dL)</td>\n",
       "      <td>2 chloride mg dL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3. Fuel_Price (USD/L)</td>\n",
       "      <td>3 Fuel_Price USD losses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4. Tumor-size: 0-4, 5-9, 10-14</td>\n",
       "      <td>4 Tumor-size 0-4 5-9 10-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5. zone: 1=NE, 2=SE, 3=SW, 4=NW</td>\n",
       "      <td>5 zone 1=NE 2=SE 3=SW 4=NW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6. temperature (°C)</td>\n",
       "      <td>6 temperature °C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7. temperature (ºF)</td>\n",
       "      <td>7 temperature ºF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8. Tdewpoint (from Chievres weather station), °C</td>\n",
       "      <td>8 Tdewpoint from Chievres weather station °C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9. cm² measurement</td>\n",
       "      <td>9 cm² measurement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10. workclass</td>\n",
       "      <td>10 workclass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11. landmass</td>\n",
       "      <td>11 landmass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12. thickness (mm³)</td>\n",
       "      <td>12 thickness mm³</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13. concentration: 5mg/dL</td>\n",
       "      <td>13 concentration 5mg dL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14. value: 10cm³</td>\n",
       "      <td>14 value 10cm³</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15. intensity: 5³, 10²</td>\n",
       "      <td>15 intensity 5³ 10²</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16. 0-1 category</td>\n",
       "      <td>16 0-1 category</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17. 1=Red, 2=Blue, 3=Green</td>\n",
       "      <td>17 1=Red 2=Blue 3=Green</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18. percent (%)</td>\n",
       "      <td>18 percent %</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19. velocity (km/h)</td>\n",
       "      <td>19 velocity km hits</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20. area: 10cm2, 10cm³</td>\n",
       "      <td>20 area 10cm2 10cm³</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21. Alcohol (%)</td>\n",
       "      <td>21 Alcohol %</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22. BMI (kg/m²)</td>\n",
       "      <td>22 body mass index kg m²</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23. air_quality_index (AQI)</td>\n",
       "      <td>23 air_quality_index AQI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24. mean-pH</td>\n",
       "      <td>24 mean-pH</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Original Column  \\\n",
       "0                               1. chlorides (mg/dL)   \n",
       "1                                2. chloride (mg/dL)   \n",
       "2                              3. Fuel_Price (USD/L)   \n",
       "3                     4. Tumor-size: 0-4, 5-9, 10-14   \n",
       "4                    5. zone: 1=NE, 2=SE, 3=SW, 4=NW   \n",
       "5                                6. temperature (°C)   \n",
       "6                                7. temperature (ºF)   \n",
       "7   8. Tdewpoint (from Chievres weather station), °C   \n",
       "8                                 9. cm² measurement   \n",
       "9                                      10. workclass   \n",
       "10                                      11. landmass   \n",
       "11                               12. thickness (mm³)   \n",
       "12                         13. concentration: 5mg/dL   \n",
       "13                                  14. value: 10cm³   \n",
       "14                            15. intensity: 5³, 10²   \n",
       "15                                  16. 0-1 category   \n",
       "16                        17. 1=Red, 2=Blue, 3=Green   \n",
       "17                                   18. percent (%)   \n",
       "18                               19. velocity (km/h)   \n",
       "19                            20. area: 10cm2, 10cm³   \n",
       "20                                   21. Alcohol (%)   \n",
       "21                                   22. BMI (kg/m²)   \n",
       "22                       23. air_quality_index (AQI)   \n",
       "23                                       24. mean-pH   \n",
       "\n",
       "                                    AbbrExpanded  \n",
       "0                              1 chlorides mg dL  \n",
       "1                               2 chloride mg dL  \n",
       "2                        3 Fuel_Price USD losses  \n",
       "3                     4 Tumor-size 0-4 5-9 10-14  \n",
       "4                     5 zone 1=NE 2=SE 3=SW 4=NW  \n",
       "5                               6 temperature °C  \n",
       "6                               7 temperature ºF  \n",
       "7   8 Tdewpoint from Chievres weather station °C  \n",
       "8                              9 cm² measurement  \n",
       "9                                   10 workclass  \n",
       "10                                   11 landmass  \n",
       "11                              12 thickness mm³  \n",
       "12                       13 concentration 5mg dL  \n",
       "13                                14 value 10cm³  \n",
       "14                           15 intensity 5³ 10²  \n",
       "15                               16 0-1 category  \n",
       "16                       17 1=Red 2=Blue 3=Green  \n",
       "17                                  18 percent %  \n",
       "18                           19 velocity km hits  \n",
       "19                           20 area 10cm2 10cm³  \n",
       "20                                  21 Alcohol %  \n",
       "21                      22 body mass index kg m²  \n",
       "22                      23 air_quality_index AQI  \n",
       "23                                    24 mean-pH  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def replace_abbreviations(text, abbreviations_dict):\n",
    "    tokens = re.findall(\n",
    "        r'\\b\\w+(?:[-=]\\w+)*\\b'          # Words, with hyphens/equals (like 0-4, 1=NE)\n",
    "        r'|[=]'                         # Standalone equal signs\n",
    "        r'|[°º][CFK]'                   # °C, ºF, etc.\n",
    "        r'|[°º\\-]+'                     # Standalone degree/hyphens\n",
    "        r'|[a-zA-Z]+/[a-zA-Z]+(?:[²³μµ]?)'   # mg/dL, kg/m², µg/m³, cm², etc.\n",
    "        r'|\\d+[²³]?'                    # 10², 5³ (numbers with superscripts)\n",
    "        r'|%'                           # <- add this line to capture % as a token\n",
    "        , text\n",
    "    )\n",
    "    replaced_tokens = [abbreviations_dict.get(token.lower(), token) for token in tokens]\n",
    "    return \" \".join(replaced_tokens)\n",
    "\n",
    "target_words_dict = dictionary\n",
    "description_words_dict = dictionary\n",
    "\n",
    "test_df = pd.DataFrame({\n",
    "    \"Original Column\": [\n",
    "        \"1. chlorides (mg/dL)\",                # plural with unit\n",
    "        \"2. chloride (mg/dL)\",                 # singular with unit\n",
    "        \"3. Fuel_Price (USD/L)\",               # phrase with underscore, unit\n",
    "        \"4. Tumor-size: 0-4, 5-9, 10-14\",      # category ranges with hyphens\n",
    "        \"5. zone: 1=NE, 2=SE, 3=SW, 4=NW\",     # code marker with equals\n",
    "        \"6. temperature (°C)\",                 # temperature symbol\n",
    "        \"7. temperature (ºF)\",                 # alternate degree symbol\n",
    "        \"8. Tdewpoint (from Chievres weather station), °C\", # degree symbol at end\n",
    "        \"9. cm² measurement\",                  # superscript unit\n",
    "        \"10. workclass\",                       # compound word\n",
    "        \"11. landmass\",                        # compound word\n",
    "        \"12. thickness (mm³)\",                 # unit with superscript ³\n",
    "        \"13. concentration: 5mg/dL\",           # value with unit\n",
    "        \"14. value: 10cm³\",                    # value with unit\n",
    "        \"15. intensity: 5³, 10²\",              # numeric with superscripts\n",
    "        \"16. 0-1 category\",                    # hyphen, short\n",
    "        \"17. 1=Red, 2=Blue, 3=Green\",          # equals for codes\n",
    "        \"18. percent (%)\",                     # symbol in column\n",
    "        \"19. velocity (km/h)\",                 # unit with slash\n",
    "        \"20. area: 10cm2, 10cm³\",              # unit, no symbol and symbol\n",
    "        \"21. Alcohol (%)\",                     # percent\n",
    "        \"22. BMI (kg/m²)\",                     # slash, superscript\n",
    "        \"23. air_quality_index (AQI)\",         # abbreviation as token\n",
    "        \"24. mean-pH\",                         # hyphen in column name\n",
    "    ]\n",
    "})\n",
    "\n",
    "# Apply the abbreviation/tokenizer function to every row\n",
    "test_df['AbbrExpanded'] = test_df['Original Column'].apply(lambda x: replace_abbreviations(str(x), abbreviations_dict))\n",
    "\n",
    "# Display original and processed columns side by side for easy comparison\n",
    "pd.set_option('display.max_colwidth', 200)\n",
    "test_df[['Original Column', 'AbbrExpanded']]\n",
    "\n",
    "#print(f\"Last run on: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split Camel Case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reviews source urls\n",
      "prices source urls\n",
      "source urls\n",
      "url length\n",
      "nation flag url\n",
      "urls\n",
      "jsonfile url\n",
      "odids\n",
      "odid\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def split_camel_case(s):\n",
    "    if s.lower() == 'ph':\n",
    "        return 'ph'\n",
    "    # Split on separators\n",
    "    tokens = re.split(r'[\\s._\\-]+', s)\n",
    "    processed_tokens = []\n",
    "\n",
    "    for token in tokens:\n",
    "        if not token:\n",
    "            continue\n",
    "        # If all uppercase or digits, keep as is\n",
    "        if token.isupper() or token.isdigit():\n",
    "            processed_tokens.append(token.lower())\n",
    "            continue\n",
    "        # If all-uppercase+digits, keep as is\n",
    "        if re.match(r'^[A-Z]{2,}\\d+$', token):\n",
    "            processed_tokens.append(token.lower())\n",
    "            continue\n",
    "\n",
    "        # Character-by-character scan\n",
    "        words = []\n",
    "        current = ''\n",
    "        i = 0\n",
    "        while i < len(token):\n",
    "            c = token[i]\n",
    "            if current == '':\n",
    "                current = c\n",
    "            elif (\n",
    "                # lower->upper transition\n",
    "                (current[-1].islower() and c.isupper()) or\n",
    "                # digit->letter or letter->digit\n",
    "                (current[-1].isdigit() and c.isalpha()) or\n",
    "                (current[-1].isalpha() and c.isdigit())\n",
    "            ):\n",
    "                words.append(current)\n",
    "                current = c\n",
    "            else:\n",
    "                current += c\n",
    "            i += 1\n",
    "        if current:\n",
    "            words.append(current)\n",
    "\n",
    "        # Now check if the last two or more are all caps: join them!\n",
    "        if len(words) >= 2 and all(w.isupper() for w in words[-2:]) and len(''.join(words[-2:])) >= 2:\n",
    "            # Join last all-cap runs\n",
    "            n = len(words) - 1\n",
    "            while n > 0 and words[n].isupper():\n",
    "                n -= 1\n",
    "            # All uppercase words from n+1 to end are the tail\n",
    "            head = words[:n+1]\n",
    "            tail = ''.join(words[n+1:])\n",
    "            processed_tokens.extend([w.lower() for w in head if w])\n",
    "            if tail:\n",
    "                processed_tokens.append(tail.lower())\n",
    "        else:\n",
    "            processed_tokens.extend([w.lower() for w in words if w])\n",
    "\n",
    "    return ' '.join(processed_tokens)\n",
    "\n",
    "print(split_camel_case(\"reviews.sourceURLs\"))   # reviews source urls\n",
    "print(split_camel_case(\"prices.sourceURLs\"))    # prices source urls\n",
    "print(split_camel_case(\"sourceURLs\"))           # source urls\n",
    "print(split_camel_case(\"UrlLength\"))            # url length\n",
    "print(split_camel_case(\"nation_flag_url\"))      # nation flag url\n",
    "print(split_camel_case(\"URLs\"))              # mean ph\n",
    "print(split_camel_case(\"JSONFileURL\"))          # json file url\n",
    "print(split_camel_case(\"ODIDs\"))                # odids\n",
    "print(split_camel_case(\"ODID\"))                # odid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset_index</th>\n",
       "      <th>name</th>\n",
       "      <th>area</th>\n",
       "      <th>Original Column</th>\n",
       "      <th>ID</th>\n",
       "      <th>Column</th>\n",
       "      <th>Path_Column</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>r1_test_metadata.jsonl</td>\n",
       "      <td>SemTabTest</td>\n",
       "      <td>SemTab2024</td>\n",
       "      <td>1.  ALT(m)</td>\n",
       "      <td>1</td>\n",
       "      <td>ALT(m)</td>\n",
       "      <td>1146722_1_7558140036342906956_ALT(m)</td>\n",
       "      <td>http://dbpedia.org/ontology/elevation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>r1_test_metadata.jsonl</td>\n",
       "      <td>SemTabTest</td>\n",
       "      <td>SemTab2024</td>\n",
       "      <td>2.  Endroit</td>\n",
       "      <td>2</td>\n",
       "      <td>Endroit</td>\n",
       "      <td>11599512_1_280388135214354946_Endroit</td>\n",
       "      <td>http://dbpedia.org/ontology/region</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>r1_test_metadata.jsonl</td>\n",
       "      <td>SemTabTest</td>\n",
       "      <td>SemTab2024</td>\n",
       "      <td>3.  AUReleaseDate</td>\n",
       "      <td>3</td>\n",
       "      <td>AUReleaseDate</td>\n",
       "      <td>11833461_1_3811022039809817402_AUReleaseDate</td>\n",
       "      <td>http://dbpedia.org/ontology/releaseDate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>r1_test_metadata.jsonl</td>\n",
       "      <td>SemTabTest</td>\n",
       "      <td>SemTab2024</td>\n",
       "      <td>4.  EUReleaseDate</td>\n",
       "      <td>4</td>\n",
       "      <td>EUReleaseDate</td>\n",
       "      <td>11833461_1_3811022039809817402_EUReleaseDate</td>\n",
       "      <td>http://dbpedia.org/ontology/releaseDate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>r1_test_metadata.jsonl</td>\n",
       "      <td>SemTabTest</td>\n",
       "      <td>SemTab2024</td>\n",
       "      <td>5.  Publisher</td>\n",
       "      <td>5</td>\n",
       "      <td>Publisher</td>\n",
       "      <td>11833461_1_3811022039809817402_Publisher</td>\n",
       "      <td>http://dbpedia.org/ontology/publisher</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>r1_test_metadata.jsonl</td>\n",
       "      <td>SemTabTest</td>\n",
       "      <td>SemTab2024</td>\n",
       "      <td>137.  Alphabeticcode</td>\n",
       "      <td>137</td>\n",
       "      <td>Alphabeticcode</td>\n",
       "      <td>97941125_0_8220652154649529701_Alphabeticcode</td>\n",
       "      <td>http://dbpedia.org/ontology/currencyCode</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>r1_test_metadata.jsonl</td>\n",
       "      <td>SemTabTest</td>\n",
       "      <td>SemTab2024</td>\n",
       "      <td>138.  Numericcode</td>\n",
       "      <td>138</td>\n",
       "      <td>Numericcode</td>\n",
       "      <td>97941125_0_8220652154649529701_Numericcode</td>\n",
       "      <td>http://dbpedia.org/ontology/code</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>r1_test_metadata.jsonl</td>\n",
       "      <td>SemTabTest</td>\n",
       "      <td>SemTab2024</td>\n",
       "      <td>139.  Symbol</td>\n",
       "      <td>139</td>\n",
       "      <td>Symbol</td>\n",
       "      <td>97941125_0_8220652154649529701_Symbol</td>\n",
       "      <td>http://dbpedia.org/ontology/symbol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>r1_test_metadata.jsonl</td>\n",
       "      <td>SemTabTest</td>\n",
       "      <td>SemTab2024</td>\n",
       "      <td>140.  Spouse</td>\n",
       "      <td>140</td>\n",
       "      <td>Spouse</td>\n",
       "      <td>98312357_0_6395417306876145729_Spouse</td>\n",
       "      <td>http://dbpedia.org/ontology/spouse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>r1_test_metadata.jsonl</td>\n",
       "      <td>SemTabTest</td>\n",
       "      <td>SemTab2024</td>\n",
       "      <td>141.  Basincountries</td>\n",
       "      <td>141</td>\n",
       "      <td>Basincountries</td>\n",
       "      <td>98929678_0_3700213490979945526_Basincountries</td>\n",
       "      <td>http://dbpedia.org/ontology/country</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>141 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              dataset_index        name        area       Original Column  \\\n",
       "0    r1_test_metadata.jsonl  SemTabTest  SemTab2024            1.  ALT(m)   \n",
       "1    r1_test_metadata.jsonl  SemTabTest  SemTab2024           2.  Endroit   \n",
       "2    r1_test_metadata.jsonl  SemTabTest  SemTab2024     3.  AUReleaseDate   \n",
       "3    r1_test_metadata.jsonl  SemTabTest  SemTab2024     4.  EUReleaseDate   \n",
       "4    r1_test_metadata.jsonl  SemTabTest  SemTab2024         5.  Publisher   \n",
       "..                      ...         ...         ...                   ...   \n",
       "136  r1_test_metadata.jsonl  SemTabTest  SemTab2024  137.  Alphabeticcode   \n",
       "137  r1_test_metadata.jsonl  SemTabTest  SemTab2024     138.  Numericcode   \n",
       "138  r1_test_metadata.jsonl  SemTabTest  SemTab2024          139.  Symbol   \n",
       "139  r1_test_metadata.jsonl  SemTabTest  SemTab2024          140.  Spouse   \n",
       "140  r1_test_metadata.jsonl  SemTabTest  SemTab2024  141.  Basincountries   \n",
       "\n",
       "      ID          Column                                    Path_Column  \\\n",
       "0      1          ALT(m)           1146722_1_7558140036342906956_ALT(m)   \n",
       "1      2         Endroit          11599512_1_280388135214354946_Endroit   \n",
       "2      3   AUReleaseDate   11833461_1_3811022039809817402_AUReleaseDate   \n",
       "3      4   EUReleaseDate   11833461_1_3811022039809817402_EUReleaseDate   \n",
       "4      5       Publisher       11833461_1_3811022039809817402_Publisher   \n",
       "..   ...             ...                                            ...   \n",
       "136  137  Alphabeticcode  97941125_0_8220652154649529701_Alphabeticcode   \n",
       "137  138     Numericcode     97941125_0_8220652154649529701_Numericcode   \n",
       "138  139          Symbol          97941125_0_8220652154649529701_Symbol   \n",
       "139  140          Spouse          98312357_0_6395417306876145729_Spouse   \n",
       "140  141  Basincountries  98929678_0_3700213490979945526_Basincountries   \n",
       "\n",
       "                                          URL  \n",
       "0       http://dbpedia.org/ontology/elevation  \n",
       "1          http://dbpedia.org/ontology/region  \n",
       "2     http://dbpedia.org/ontology/releaseDate  \n",
       "3     http://dbpedia.org/ontology/releaseDate  \n",
       "4       http://dbpedia.org/ontology/publisher  \n",
       "..                                        ...  \n",
       "136  http://dbpedia.org/ontology/currencyCode  \n",
       "137          http://dbpedia.org/ontology/code  \n",
       "138        http://dbpedia.org/ontology/symbol  \n",
       "139        http://dbpedia.org/ontology/spouse  \n",
       "140       http://dbpedia.org/ontology/country  \n",
       "\n",
       "[141 rows x 8 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_xlsx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset_index</th>\n",
       "      <th>name</th>\n",
       "      <th>area</th>\n",
       "      <th>Original Column</th>\n",
       "      <th>ID</th>\n",
       "      <th>Column</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>r1_test_metadata.jsonl</td>\n",
       "      <td>SemTabTest</td>\n",
       "      <td>SemTab2024</td>\n",
       "      <td>1.  ALT(m)</td>\n",
       "      <td>1</td>\n",
       "      <td>ALT</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>r1_test_metadata.jsonl</td>\n",
       "      <td>SemTabTest</td>\n",
       "      <td>SemTab2024</td>\n",
       "      <td>2.  Endroit</td>\n",
       "      <td>2</td>\n",
       "      <td>Endroit</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>r1_test_metadata.jsonl</td>\n",
       "      <td>SemTabTest</td>\n",
       "      <td>SemTab2024</td>\n",
       "      <td>3.  AUReleaseDate</td>\n",
       "      <td>3</td>\n",
       "      <td>AUReleaseDate</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>r1_test_metadata.jsonl</td>\n",
       "      <td>SemTabTest</td>\n",
       "      <td>SemTab2024</td>\n",
       "      <td>4.  EUReleaseDate</td>\n",
       "      <td>4</td>\n",
       "      <td>EUReleaseDate</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>r1_test_metadata.jsonl</td>\n",
       "      <td>SemTabTest</td>\n",
       "      <td>SemTab2024</td>\n",
       "      <td>5.  Publisher</td>\n",
       "      <td>5</td>\n",
       "      <td>Publisher</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>r1_test_metadata.jsonl</td>\n",
       "      <td>SemTabTest</td>\n",
       "      <td>SemTab2024</td>\n",
       "      <td>137.  Alphabeticcode</td>\n",
       "      <td>137</td>\n",
       "      <td>Alphabeticcode</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>r1_test_metadata.jsonl</td>\n",
       "      <td>SemTabTest</td>\n",
       "      <td>SemTab2024</td>\n",
       "      <td>138.  Numericcode</td>\n",
       "      <td>138</td>\n",
       "      <td>Numericcode</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>r1_test_metadata.jsonl</td>\n",
       "      <td>SemTabTest</td>\n",
       "      <td>SemTab2024</td>\n",
       "      <td>139.  Symbol</td>\n",
       "      <td>139</td>\n",
       "      <td>Symbol</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>r1_test_metadata.jsonl</td>\n",
       "      <td>SemTabTest</td>\n",
       "      <td>SemTab2024</td>\n",
       "      <td>140.  Spouse</td>\n",
       "      <td>140</td>\n",
       "      <td>Spouse</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>r1_test_metadata.jsonl</td>\n",
       "      <td>SemTabTest</td>\n",
       "      <td>SemTab2024</td>\n",
       "      <td>141.  Basincountries</td>\n",
       "      <td>141</td>\n",
       "      <td>Basincountries</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>141 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              dataset_index        name        area       Original Column  \\\n",
       "0    r1_test_metadata.jsonl  SemTabTest  SemTab2024            1.  ALT(m)   \n",
       "1    r1_test_metadata.jsonl  SemTabTest  SemTab2024           2.  Endroit   \n",
       "2    r1_test_metadata.jsonl  SemTabTest  SemTab2024     3.  AUReleaseDate   \n",
       "3    r1_test_metadata.jsonl  SemTabTest  SemTab2024     4.  EUReleaseDate   \n",
       "4    r1_test_metadata.jsonl  SemTabTest  SemTab2024         5.  Publisher   \n",
       "..                      ...         ...         ...                   ...   \n",
       "136  r1_test_metadata.jsonl  SemTabTest  SemTab2024  137.  Alphabeticcode   \n",
       "137  r1_test_metadata.jsonl  SemTabTest  SemTab2024     138.  Numericcode   \n",
       "138  r1_test_metadata.jsonl  SemTabTest  SemTab2024          139.  Symbol   \n",
       "139  r1_test_metadata.jsonl  SemTabTest  SemTab2024          140.  Spouse   \n",
       "140  r1_test_metadata.jsonl  SemTabTest  SemTab2024  141.  Basincountries   \n",
       "\n",
       "      ID          Column Description  \n",
       "0      1             ALT           m  \n",
       "1      2         Endroit         NaN  \n",
       "2      3   AUReleaseDate         NaN  \n",
       "3      4   EUReleaseDate         NaN  \n",
       "4      5       Publisher         NaN  \n",
       "..   ...             ...         ...  \n",
       "136  137  Alphabeticcode         NaN  \n",
       "137  138     Numericcode         NaN  \n",
       "138  139          Symbol         NaN  \n",
       "139  140          Spouse         NaN  \n",
       "140  141  Basincountries         NaN  \n",
       "\n",
       "[141 rows x 7 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_columns_df = clean_columns(columns_xlsx.copy())\n",
    "cleaned_columns_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last run on: 2025-11-07 21:44:15\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset_index</th>\n",
       "      <th>name</th>\n",
       "      <th>area</th>\n",
       "      <th>Original Column</th>\n",
       "      <th>ID</th>\n",
       "      <th>Column</th>\n",
       "      <th>Description</th>\n",
       "      <th>CleanedColumn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>r1_test_metadata.jsonl</td>\n",
       "      <td>SemTabTest</td>\n",
       "      <td>SemTab2024</td>\n",
       "      <td>1.  ALT(m)</td>\n",
       "      <td>1</td>\n",
       "      <td>ALT</td>\n",
       "      <td>m</td>\n",
       "      <td>alt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>r1_test_metadata.jsonl</td>\n",
       "      <td>SemTabTest</td>\n",
       "      <td>SemTab2024</td>\n",
       "      <td>2.  Endroit</td>\n",
       "      <td>2</td>\n",
       "      <td>Endroit</td>\n",
       "      <td>NaN</td>\n",
       "      <td>endroit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>r1_test_metadata.jsonl</td>\n",
       "      <td>SemTabTest</td>\n",
       "      <td>SemTab2024</td>\n",
       "      <td>3.  AUReleaseDate</td>\n",
       "      <td>3</td>\n",
       "      <td>AUReleaseDate</td>\n",
       "      <td>NaN</td>\n",
       "      <td>aurelease date</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>r1_test_metadata.jsonl</td>\n",
       "      <td>SemTabTest</td>\n",
       "      <td>SemTab2024</td>\n",
       "      <td>4.  EUReleaseDate</td>\n",
       "      <td>4</td>\n",
       "      <td>EUReleaseDate</td>\n",
       "      <td>NaN</td>\n",
       "      <td>eurelease date</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>r1_test_metadata.jsonl</td>\n",
       "      <td>SemTabTest</td>\n",
       "      <td>SemTab2024</td>\n",
       "      <td>5.  Publisher</td>\n",
       "      <td>5</td>\n",
       "      <td>Publisher</td>\n",
       "      <td>NaN</td>\n",
       "      <td>publisher</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>r1_test_metadata.jsonl</td>\n",
       "      <td>SemTabTest</td>\n",
       "      <td>SemTab2024</td>\n",
       "      <td>137.  Alphabeticcode</td>\n",
       "      <td>137</td>\n",
       "      <td>Alphabeticcode</td>\n",
       "      <td>NaN</td>\n",
       "      <td>alphabeticcode</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>r1_test_metadata.jsonl</td>\n",
       "      <td>SemTabTest</td>\n",
       "      <td>SemTab2024</td>\n",
       "      <td>138.  Numericcode</td>\n",
       "      <td>138</td>\n",
       "      <td>Numericcode</td>\n",
       "      <td>NaN</td>\n",
       "      <td>numericcode</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>r1_test_metadata.jsonl</td>\n",
       "      <td>SemTabTest</td>\n",
       "      <td>SemTab2024</td>\n",
       "      <td>139.  Symbol</td>\n",
       "      <td>139</td>\n",
       "      <td>Symbol</td>\n",
       "      <td>NaN</td>\n",
       "      <td>symbol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>r1_test_metadata.jsonl</td>\n",
       "      <td>SemTabTest</td>\n",
       "      <td>SemTab2024</td>\n",
       "      <td>140.  Spouse</td>\n",
       "      <td>140</td>\n",
       "      <td>Spouse</td>\n",
       "      <td>NaN</td>\n",
       "      <td>spouse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>r1_test_metadata.jsonl</td>\n",
       "      <td>SemTabTest</td>\n",
       "      <td>SemTab2024</td>\n",
       "      <td>141.  Basincountries</td>\n",
       "      <td>141</td>\n",
       "      <td>Basincountries</td>\n",
       "      <td>NaN</td>\n",
       "      <td>basincountries</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>141 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              dataset_index        name        area       Original Column  \\\n",
       "0    r1_test_metadata.jsonl  SemTabTest  SemTab2024            1.  ALT(m)   \n",
       "1    r1_test_metadata.jsonl  SemTabTest  SemTab2024           2.  Endroit   \n",
       "2    r1_test_metadata.jsonl  SemTabTest  SemTab2024     3.  AUReleaseDate   \n",
       "3    r1_test_metadata.jsonl  SemTabTest  SemTab2024     4.  EUReleaseDate   \n",
       "4    r1_test_metadata.jsonl  SemTabTest  SemTab2024         5.  Publisher   \n",
       "..                      ...         ...         ...                   ...   \n",
       "136  r1_test_metadata.jsonl  SemTabTest  SemTab2024  137.  Alphabeticcode   \n",
       "137  r1_test_metadata.jsonl  SemTabTest  SemTab2024     138.  Numericcode   \n",
       "138  r1_test_metadata.jsonl  SemTabTest  SemTab2024          139.  Symbol   \n",
       "139  r1_test_metadata.jsonl  SemTabTest  SemTab2024          140.  Spouse   \n",
       "140  r1_test_metadata.jsonl  SemTabTest  SemTab2024  141.  Basincountries   \n",
       "\n",
       "      ID          Column Description   CleanedColumn  \n",
       "0      1             ALT           m             alt  \n",
       "1      2         Endroit         NaN         endroit  \n",
       "2      3   AUReleaseDate         NaN  aurelease date  \n",
       "3      4   EUReleaseDate         NaN  eurelease date  \n",
       "4      5       Publisher         NaN       publisher  \n",
       "..   ...             ...         ...             ...  \n",
       "136  137  Alphabeticcode         NaN  alphabeticcode  \n",
       "137  138     Numericcode         NaN     numericcode  \n",
       "138  139          Symbol         NaN          symbol  \n",
       "139  140          Spouse         NaN          spouse  \n",
       "140  141  Basincountries         NaN  basincountries  \n",
       "\n",
       "[141 rows x 8 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preprocess_columns(df):\n",
    "        \n",
    "    # Only convert \"Column\" to string type for non-null values and then to lowercase to create \"CleanedColumn\"\n",
    "    mask = df['Column'].notna()\n",
    "\n",
    "    df.loc[mask, 'Column'] = df.loc[mask, 'Column'].str.replace('#', 'number', regex=False)\n",
    "    \n",
    "    df.loc[mask, 'CleanedColumn'] = df.loc[mask, 'Column'].astype(str).apply(split_camel_case)\n",
    "    \n",
    "    # Remove '-' and '_' characters only for non-null values\n",
    "    mask = df['CleanedColumn'].notna()\n",
    "    df.loc[mask, 'CleanedColumn'] = df.loc[mask, 'CleanedColumn'].str.replace('[-_]', ' ', regex=True)\n",
    "\n",
    "    # Apply abbreviations dictionary to Description\n",
    "    mask = df['Description'].notna()\n",
    "    df.loc[mask, 'Description'] = df.loc[mask, 'Description'].apply(lambda x: replace_abbreviations(x, abbreviations_dict))\n",
    " \n",
    "    return df\n",
    "\n",
    "# Clean the columns\n",
    "\n",
    "cleaned_columns_df = clean_columns(columns_xlsx.copy())\n",
    "\n",
    "# Preprocess the column names\n",
    "preprocessed_columns_df = preprocess_columns(cleaned_columns_df)\n",
    "print(f\"Last run on: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "\n",
    "preprocessed_columns_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KG Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded DBpedia labels: ['a side', 'abbeychurch blessing', 'abbeychurch blessing charge', 'abbreviation', 'able to grind'] ...\n",
      "DBpedia label to id (sample): {'a side': 'http://dbpedia.org/ontology/aSide', 'abbeychurch blessing': 'http://dbpedia.org/ontology/abbeychurchBlessing', 'abbeychurch blessing charge': 'http://dbpedia.org/ontology/abbeychurchBlessingCharge'}\n",
      "Loaded Schema.org labels: ['3 d model', 'abdomen', 'about', 'about page', 'abridged'] ...\n",
      "Schema.org label to id (sample): {'3 d model': 'https://schema.org/3DModel', 'abdomen': 'https://schema.org/Abdomen', 'about': 'https://schema.org/about'}\n",
      "Gensim FastText model loaded. Dimension: 300\n",
      "Embedding for 'birth date': [ 0.00283275  0.0443643  -0.06757186  0.06091432  0.00819952]\n",
      "Sample DBpedia label embedding shape: (300,)\n",
      "First 5 dims of first embedding: [ 0.01555624 -0.24466786  0.00117554 -0.002059   -0.03555111]\n",
      "Syntactic match (DBpedia) for 'birth date': http://dbpedia.org/ontology/birthDate\n",
      "Syntactic match (Schema.org) for 'birth date': https://schema.org/birthDate\n",
      "Syntactic match (DBpedia) for 'organization': http://dbpedia.org/ontology/Organization\n",
      "Syntactic match (Schema.org) for 'organization': https://schema.org/Organization\n",
      "Syntactic match (DBpedia) for 'assets': http://dbpedia.org/ontology/assets\n",
      "Syntactic match (Schema.org) for 'assets': None\n",
      "Syntactic match (DBpedia) for 'zip code': http://dbpedia.org/ontology/zipCode\n",
      "Syntactic match (Schema.org) for 'zip code': None\n",
      "Syntactic match (DBpedia) for 'unknownfield': None\n",
      "Syntactic match (Schema.org) for 'unknownfield': None\n",
      "Semantic match (DBpedia) for 'assets': http://dbpedia.org/ontology/assets 1.0000000542607073\n",
      "Semantic match (Schema.org) for 'assets': None 0.4719898244507163\n",
      "Semantic match (DBpedia) for 'amt': None 0.41080459931294044\n",
      "Semantic match (Schema.org) for 'amt': None 0.5676016132668965\n",
      "Semantic match (DBpedia) for 'org unit': None 0.47278003880190883\n",
      "Semantic match (Schema.org) for 'org unit': None 0.4896823450750818\n",
      "Semantic match (DBpedia) for 'unknownfield': None 0.4986249117228689\n",
      "Semantic match (Schema.org) for 'unknownfield': None 0.4192307349239801\n",
      "Last run on: 2025-11-07 21:49:35\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import difflib\n",
    "import numpy as np\n",
    "from gensim.models.fasttext import load_facebook_vectors\n",
    "from datetime import datetime  # you referenced datetime at the end\n",
    "\n",
    "# =========================================================\n",
    "# 1. Load DBpedia and Schema.org terms\n",
    "# =========================================================\n",
    "dbpedia_terms_df = pd.read_excel('dbpedia.xlsx')\n",
    "# labels are kept lowercase for matching\n",
    "dbpedia_labels = dbpedia_terms_df['cleaned_label'].astype(str).str.lower().tolist()\n",
    "dbpedia_ids = dbpedia_terms_df['id'].astype(str).tolist()\n",
    "dbpedia_label_to_id = dict(zip(dbpedia_labels, dbpedia_ids))\n",
    "\n",
    "schema_terms_df = pd.read_excel('schema.xlsx')\n",
    "schema_labels = schema_terms_df['cleaned_label'].astype(str).str.lower().tolist()\n",
    "schema_ids = schema_terms_df['id'].astype(str).tolist()\n",
    "schema_label_to_id = dict(zip(schema_labels, schema_ids))\n",
    "\n",
    "print(\"Loaded DBpedia labels:\", dbpedia_labels[:5], \"...\")\n",
    "print(\"DBpedia label to id (sample):\", {k: dbpedia_label_to_id[k] for k in dbpedia_labels[:3]})\n",
    "print(\"Loaded Schema.org labels:\", schema_labels[:5], \"...\")\n",
    "print(\"Schema.org label to id (sample):\", {k: schema_label_to_id[k] for k in schema_labels[:3]})\n",
    "\n",
    "# =========================================================\n",
    "# 1.1 map “tail in lowercase → real URI” for DBpedia\n",
    "# =========================================================\n",
    "dbpedia_lower_tail_to_uri = {}\n",
    "for uri in dbpedia_ids:\n",
    "    tail = uri.rsplit('/', 1)[-1]\n",
    "    lower_tail = tail.lower()\n",
    "    dbpedia_lower_tail_to_uri.setdefault(lower_tail, uri)\n",
    "\n",
    "\n",
    "def normalise_dbpedia_uri_safely(uri: str) -> str:\n",
    "    \"\"\"\n",
    "    If DBpedia has a lowercase version of this URI tail, return it.\n",
    "    Otherwise keep the original URI (for things like dbo:Airport).\n",
    "    \"\"\"\n",
    "    if not uri:\n",
    "        return uri\n",
    "    base, tail = uri.rsplit('/', 1)\n",
    "    lower_tail = tail.lower()\n",
    "    if lower_tail in dbpedia_lower_tail_to_uri:\n",
    "        return dbpedia_lower_tail_to_uri[lower_tail]\n",
    "    return uri\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# 2. Syntactic match\n",
    "# =========================================================\n",
    "def syntactic_match(header, labels_list, label_to_id, threshold=0.9, kg=\"dbpedia\"):\n",
    "    header_l = header.strip().lower()\n",
    "    # exact\n",
    "    if header_l in label_to_id:\n",
    "        uri = label_to_id[header_l]\n",
    "        if kg == \"dbpedia\":\n",
    "            uri = normalise_dbpedia_uri_safely(uri)\n",
    "        return uri\n",
    "\n",
    "    # close\n",
    "    matches = difflib.get_close_matches(header_l, labels_list, n=1, cutoff=threshold)\n",
    "    if matches:\n",
    "        uri = label_to_id[matches[0]]\n",
    "        if kg == \"dbpedia\":\n",
    "            uri = normalise_dbpedia_uri_safely(uri)\n",
    "        return uri\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# 3. Load FastText\n",
    "# =========================================================\n",
    "fasttext_model = load_facebook_vectors('cc.en.300.bin')  # update path if needed\n",
    "print(\"Gensim FastText model loaded. Dimension:\", fasttext_model.vector_size)\n",
    "\n",
    "\n",
    "def get_embedding(text):\n",
    "    words = text.split()\n",
    "    vectors = [fasttext_model[w] for w in words if w in fasttext_model]\n",
    "    if not vectors:\n",
    "        return np.zeros(fasttext_model.vector_size)\n",
    "    return np.mean(vectors, axis=0)\n",
    "\n",
    "\n",
    "print(\"Embedding for 'birth date':\", get_embedding(\"birth date\")[:5])\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# 4. Semantic match\n",
    "#    IMPORTANT CHANGE: first check if the header is an exact label.\n",
    "#    If yes, return that right away so we don’t overwrite it with a\n",
    "#    capitalised near-duplicate.\n",
    "# =========================================================\n",
    "def semantic_match(header,\n",
    "                   labels_list,\n",
    "                   label_to_id,\n",
    "                   embeddings_dict,\n",
    "                   similarity_threshold=0.9,\n",
    "                   kg=\"dbpedia\"):\n",
    "    header_l = header.strip().lower()\n",
    "\n",
    "    # ---- NEW: respect exact ontology labels even in semantic mode ----\n",
    "    if header_l in label_to_id:\n",
    "        uri = label_to_id[header_l]\n",
    "        if kg == \"dbpedia\":\n",
    "            uri = normalise_dbpedia_uri_safely(uri)\n",
    "        # we return 1.0 here just to signal “perfect”\n",
    "        return uri, 1.0\n",
    "    # ------------------------------------------------------------------\n",
    "\n",
    "    header_emb = get_embedding(header_l)\n",
    "    best_sim = -1.0\n",
    "    best_label = None\n",
    "\n",
    "    for label, emb in embeddings_dict.items():\n",
    "        sim = np.dot(header_emb, emb) / (np.linalg.norm(header_emb) * np.linalg.norm(emb) + 1e-8)\n",
    "        if sim > best_sim:\n",
    "            best_sim = sim\n",
    "            best_label = label\n",
    "\n",
    "    if best_sim >= similarity_threshold and best_label is not None:\n",
    "        uri = label_to_id[best_label]\n",
    "        if kg == \"dbpedia\":\n",
    "            uri = normalise_dbpedia_uri_safely(uri)\n",
    "        return uri, best_sim\n",
    "\n",
    "    return None, best_sim\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# 5. Precompute embeddings\n",
    "# =========================================================\n",
    "dbpedia_embeddings = {label: get_embedding(label) for label in dbpedia_labels}\n",
    "schema_embeddings = {label: get_embedding(label) for label in schema_labels}\n",
    "\n",
    "print(\"Sample DBpedia label embedding shape:\", dbpedia_embeddings[dbpedia_labels[0]].shape)\n",
    "print(\"First 5 dims of first embedding:\", dbpedia_embeddings[dbpedia_labels[0]][:5])\n",
    "\n",
    "# =========================================================\n",
    "# 6. Quick tests\n",
    "# =========================================================\n",
    "test_headers = ['birth date', 'organization', 'assets', 'zip code', 'unknownfield']\n",
    "for th in test_headers:\n",
    "    dbp_syn = syntactic_match(th, dbpedia_labels, dbpedia_label_to_id, kg=\"dbpedia\")\n",
    "    print(f\"Syntactic match (DBpedia) for '{th}':\", dbp_syn)\n",
    "\n",
    "    sch_syn = syntactic_match(th, schema_labels, schema_label_to_id, kg=\"schema\")\n",
    "    print(f\"Syntactic match (Schema.org) for '{th}':\", sch_syn)\n",
    "\n",
    "# headers to test semantic matching\n",
    "sem_headers = ['assets', 'amt', 'org unit', 'unknownfield', 'languages']\n",
    "for sh in sem_headers:\n",
    "    dbp_sem, dbp_sim = semantic_match(\n",
    "        sh, dbpedia_labels, dbpedia_label_to_id, dbpedia_embeddings, kg=\"dbpedia\"\n",
    "    )\n",
    "    print(f\"Semantic match (DBpedia) for '{sh}':\", dbp_sem, dbp_sim)\n",
    "\n",
    "    sch_sem, sch_sim = semantic_match(\n",
    "        sh, schema_labels, schema_label_to_id, schema_embeddings, kg=\"schema\"\n",
    "    )\n",
    "    print(f\"Semantic match (Schema.org) for '{sh}':\", sch_sem, sch_sim)\n",
    "\n",
    "print(f\"Last run on: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Substring wins] 'release date' in 'aurelease date'\n",
      "[Substring wins] 'release date' in 'eurelease date'\n",
      "[Substring wins] 'height' in 'heightinmeters'\n",
      "[Substring wins] 'code' in 'alphabeticcode'\n",
      "[Substring wins] 'code' in 'numericcode'\n",
      "[Substring wins] 'institution' in 'granting institution'\n",
      "[Substring wins] 'ratio' in 'rationale'\n",
      "[Substring wins] 'code' in 'alphabeticcode'\n",
      "[Substring wins] 'code' in 'numericcode'\n",
      "[Substring wins] 'diocese' in 'dioceses'\n",
      "[Substring wins] 'height' in 'heightinmeters'\n",
      "[Substring wins] 'code' in 'alphabeticcode'\n",
      "[Substring wins] 'code' in 'numericcode'\n",
      "[Substring wins] 'language' in 'languages'\n",
      "[Substring wins] 'language' in 'languages'\n",
      "[Substring wins] 'language' in 'languages'\n",
      "[Substring wins] 'water' in 'watergauge'\n",
      "[Substring wins] 'area' in 'landarea'\n",
      "[Substring wins] 'founder' in 'founders'\n",
      "[Substring wins] 'code' in 'alphabeticcode'\n",
      "[Substring wins] 'code' in 'numericcode'\n",
      "[Substring wins] 'release date' in 'aurelease date'\n",
      "[Substring wins] 'release date' in 'eurelease date'\n",
      "[Substring wins] 'currency' in 'currency code'\n",
      "[Substring wins] 'height' in 'heightinmeters'\n",
      "[Substring wins] 'code' in 'alphabeticcode'\n",
      "[Substring wins] 'code' in 'numericcode'\n",
      "[Substring wins] 'grant' in 'granting institution'\n",
      "[Substring wins] 'code' in 'alphabeticcode'\n",
      "[Substring wins] 'code' in 'numericcode'\n",
      "[Substring wins] 'height' in 'heightinmeters'\n",
      "[Substring wins] 'code' in 'alphabeticcode'\n",
      "[Substring wins] 'code' in 'numericcode'\n",
      "[Substring wins] 'language' in 'languages'\n",
      "[Substring wins] 'language' in 'languages'\n",
      "[Substring wins] 'language' in 'languages'\n",
      "[Substring wins] 'area' in 'landarea'\n",
      "[Substring wins] 'code' in 'alphabeticcode'\n",
      "[Substring wins] 'code' in 'numericcode'\n",
      "Last run on: 2025-11-07 21:49:54\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CleanedColumn</th>\n",
       "      <th>Description</th>\n",
       "      <th>DBpediaType</th>\n",
       "      <th>DBpediaScore</th>\n",
       "      <th>SchemaOrgType</th>\n",
       "      <th>SchemaScore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>alt</td>\n",
       "      <td>m</td>\n",
       "      <td>http://dbpedia.org/ontology/altitude</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>Nil</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>endroit</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Nil</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Nil</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aurelease date</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://dbpedia.org/ontology/releaseDate</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>https://schema.org/releaseDate</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>eurelease date</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://dbpedia.org/ontology/releaseDate</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>https://schema.org/releaseDate</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>publisher</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://dbpedia.org/ontology/publisher</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>http://dbpedia.org/ontology/publisher</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>address</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://dbpedia.org/ontology/address</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>http://dbpedia.org/ontology/address</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>format</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://dbpedia.org/ontology/format</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>https://schema.org/DigitalFormat</td>\n",
       "      <td>0.863042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>currency code</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://dbpedia.org/ontology/currencyCode</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>https://schema.org/currency</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>heightinmeters</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://dbpedia.org/ontology/height</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>https://schema.org/height</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>director</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://dbpedia.org/ontology/director</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>http://dbpedia.org/ontology/director</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>artist</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://dbpedia.org/ontology/artist</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>http://dbpedia.org/ontology/artist</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>height</td>\n",
       "      <td>free throws</td>\n",
       "      <td>http://dbpedia.org/ontology/height</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>http://dbpedia.org/ontology/height</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>state</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://dbpedia.org/ontology/state</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>http://dbpedia.org/ontology/state</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>state</td>\n",
       "      <td>Province</td>\n",
       "      <td>http://dbpedia.org/ontology/state</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>http://dbpedia.org/ontology/state</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>year</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://dbpedia.org/ontology/year</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>https://schema.org/copyrightYear</td>\n",
       "      <td>0.848724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>developer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://dbpedia.org/ontology/developer</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>Nil</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>label</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://dbpedia.org/ontology/distributingLabel</td>\n",
       "      <td>0.935610</td>\n",
       "      <td>http://dbpedia.org/ontology/recordLabel</td>\n",
       "      <td>0.892867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>publisher</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://dbpedia.org/ontology/publisher</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>http://dbpedia.org/ontology/publisher</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>cost</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://dbpedia.org/ontology/cost</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>https://schema.org/estimatedCost</td>\n",
       "      <td>0.955836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>europe</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Nil</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Nil</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>japan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Nil</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Nil</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>north america</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://dbpedia.org/ontology/northWestPlace</td>\n",
       "      <td>0.826303</td>\n",
       "      <td>Nil</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>publisher</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://dbpedia.org/ontology/publisher</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>http://dbpedia.org/ontology/publisher</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>size</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://dbpedia.org/ontology/collectionSize</td>\n",
       "      <td>0.963924</td>\n",
       "      <td>https://schema.org/size</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>system</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://dbpedia.org/ontology/systemRequirements</td>\n",
       "      <td>0.907783</td>\n",
       "      <td>http://dbpedia.org/ontology/operatingSystem</td>\n",
       "      <td>0.902147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>year</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://dbpedia.org/ontology/year</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>https://schema.org/copyrightYear</td>\n",
       "      <td>0.848724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>director</td>\n",
       "      <td>s</td>\n",
       "      <td>http://dbpedia.org/ontology/director</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>http://dbpedia.org/ontology/director</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>year</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://dbpedia.org/ontology/year</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>https://schema.org/copyrightYear</td>\n",
       "      <td>0.848724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>alphabeticcode</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://dbpedia.org/ontology/code</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>https://schema.org/Code</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>numericcode</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://dbpedia.org/ontology/code</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>https://schema.org/Code</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>genre</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://dbpedia.org/ontology/genre</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>http://dbpedia.org/ontology/genre</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>platform</td>\n",
       "      <td>s</td>\n",
       "      <td>http://dbpedia.org/ontology/computingPlatform</td>\n",
       "      <td>0.782497</td>\n",
       "      <td>https://schema.org/departurePlatform</td>\n",
       "      <td>0.760722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>year</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://dbpedia.org/ontology/year</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>https://schema.org/copyrightYear</td>\n",
       "      <td>0.848724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>developer</td>\n",
       "      <td>s</td>\n",
       "      <td>http://dbpedia.org/ontology/developer</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>Nil</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>genre</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://dbpedia.org/ontology/genre</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>http://dbpedia.org/ontology/genre</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>platform</td>\n",
       "      <td>s</td>\n",
       "      <td>http://dbpedia.org/ontology/computingPlatform</td>\n",
       "      <td>0.782497</td>\n",
       "      <td>https://schema.org/departurePlatform</td>\n",
       "      <td>0.760722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>year</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://dbpedia.org/ontology/year</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>https://schema.org/copyrightYear</td>\n",
       "      <td>0.848724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>developer</td>\n",
       "      <td>s</td>\n",
       "      <td>http://dbpedia.org/ontology/developer</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>Nil</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>genre</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://dbpedia.org/ontology/genre</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>http://dbpedia.org/ontology/genre</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>platform</td>\n",
       "      <td>s</td>\n",
       "      <td>http://dbpedia.org/ontology/computingPlatform</td>\n",
       "      <td>0.782497</td>\n",
       "      <td>https://schema.org/departurePlatform</td>\n",
       "      <td>0.760722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>year</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://dbpedia.org/ontology/year</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>https://schema.org/copyrightYear</td>\n",
       "      <td>0.848724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>developer</td>\n",
       "      <td>s</td>\n",
       "      <td>http://dbpedia.org/ontology/developer</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>Nil</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>genre</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://dbpedia.org/ontology/genre</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>http://dbpedia.org/ontology/genre</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>platform</td>\n",
       "      <td>s</td>\n",
       "      <td>http://dbpedia.org/ontology/computingPlatform</td>\n",
       "      <td>0.782497</td>\n",
       "      <td>https://schema.org/departurePlatform</td>\n",
       "      <td>0.760722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>year</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://dbpedia.org/ontology/year</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>https://schema.org/copyrightYear</td>\n",
       "      <td>0.848724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>year</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://dbpedia.org/ontology/year</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>https://schema.org/copyrightYear</td>\n",
       "      <td>0.848724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>stadt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Nil</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Nil</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>director</td>\n",
       "      <td>s</td>\n",
       "      <td>http://dbpedia.org/ontology/director</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>http://dbpedia.org/ontology/director</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>year</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://dbpedia.org/ontology/year</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>https://schema.org/copyrightYear</td>\n",
       "      <td>0.848724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>developer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://dbpedia.org/ontology/developer</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>Nil</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>platform</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://dbpedia.org/ontology/computingPlatform</td>\n",
       "      <td>0.782497</td>\n",
       "      <td>https://schema.org/departurePlatform</td>\n",
       "      <td>0.760722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>director</td>\n",
       "      <td>s</td>\n",
       "      <td>http://dbpedia.org/ontology/director</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>http://dbpedia.org/ontology/director</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>year</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://dbpedia.org/ontology/year</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>https://schema.org/copyrightYear</td>\n",
       "      <td>0.848724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>h?he</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Nil</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Nil</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>address</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://dbpedia.org/ontology/address</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>http://dbpedia.org/ontology/address</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>director</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://dbpedia.org/ontology/director</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>http://dbpedia.org/ontology/director</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>year</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://dbpedia.org/ontology/year</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>https://schema.org/copyrightYear</td>\n",
       "      <td>0.848724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>director</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://dbpedia.org/ontology/director</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>http://dbpedia.org/ontology/director</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>rel</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Nil</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Nil</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>assets</td>\n",
       "      <td>bil</td>\n",
       "      <td>http://dbpedia.org/ontology/assets</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>Nil</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     CleanedColumn  Description  \\\n",
       "0              alt            m   \n",
       "1          endroit          NaN   \n",
       "2   aurelease date          NaN   \n",
       "3   eurelease date          NaN   \n",
       "4        publisher          NaN   \n",
       "5          address          NaN   \n",
       "6           format          NaN   \n",
       "7    currency code          NaN   \n",
       "8   heightinmeters          NaN   \n",
       "9         director          NaN   \n",
       "10          artist          NaN   \n",
       "11          height  free throws   \n",
       "12           state          NaN   \n",
       "13           state     Province   \n",
       "14            year          NaN   \n",
       "15       developer          NaN   \n",
       "16           label          NaN   \n",
       "17       publisher          NaN   \n",
       "18            cost          NaN   \n",
       "19          europe          NaN   \n",
       "20           japan          NaN   \n",
       "21   north america          NaN   \n",
       "22       publisher          NaN   \n",
       "23            size          NaN   \n",
       "24          system          NaN   \n",
       "25            year          NaN   \n",
       "26        director            s   \n",
       "27            year          NaN   \n",
       "28  alphabeticcode          NaN   \n",
       "29     numericcode          NaN   \n",
       "30           genre          NaN   \n",
       "31        platform            s   \n",
       "32            year          NaN   \n",
       "33       developer            s   \n",
       "34           genre          NaN   \n",
       "35        platform            s   \n",
       "36            year          NaN   \n",
       "37       developer            s   \n",
       "38           genre          NaN   \n",
       "39        platform            s   \n",
       "40            year          NaN   \n",
       "41       developer            s   \n",
       "42           genre          NaN   \n",
       "43        platform            s   \n",
       "44            year          NaN   \n",
       "45            year          NaN   \n",
       "46           stadt          NaN   \n",
       "47        director            s   \n",
       "48            year          NaN   \n",
       "49       developer          NaN   \n",
       "50        platform          NaN   \n",
       "51        director            s   \n",
       "52            year          NaN   \n",
       "53            h?he          NaN   \n",
       "54         address          NaN   \n",
       "55        director          NaN   \n",
       "56            year          NaN   \n",
       "57        director          NaN   \n",
       "58             rel          NaN   \n",
       "59          assets          bil   \n",
       "\n",
       "                                       DBpediaType  DBpediaScore  \\\n",
       "0             http://dbpedia.org/ontology/altitude      1.000000   \n",
       "1                                              Nil      0.000000   \n",
       "2          http://dbpedia.org/ontology/releaseDate      1.000000   \n",
       "3          http://dbpedia.org/ontology/releaseDate      1.000000   \n",
       "4            http://dbpedia.org/ontology/publisher      1.000000   \n",
       "5              http://dbpedia.org/ontology/address      1.000000   \n",
       "6               http://dbpedia.org/ontology/format      1.000000   \n",
       "7         http://dbpedia.org/ontology/currencyCode      1.000000   \n",
       "8               http://dbpedia.org/ontology/height      1.000000   \n",
       "9             http://dbpedia.org/ontology/director      1.000000   \n",
       "10              http://dbpedia.org/ontology/artist      1.000000   \n",
       "11              http://dbpedia.org/ontology/height      1.000000   \n",
       "12               http://dbpedia.org/ontology/state      1.000000   \n",
       "13               http://dbpedia.org/ontology/state      1.000000   \n",
       "14                http://dbpedia.org/ontology/year      1.000000   \n",
       "15           http://dbpedia.org/ontology/developer      1.000000   \n",
       "16   http://dbpedia.org/ontology/distributingLabel      0.935610   \n",
       "17           http://dbpedia.org/ontology/publisher      1.000000   \n",
       "18                http://dbpedia.org/ontology/cost      1.000000   \n",
       "19                                             Nil      0.000000   \n",
       "20                                             Nil      0.000000   \n",
       "21      http://dbpedia.org/ontology/northWestPlace      0.826303   \n",
       "22           http://dbpedia.org/ontology/publisher      1.000000   \n",
       "23      http://dbpedia.org/ontology/collectionSize      0.963924   \n",
       "24  http://dbpedia.org/ontology/systemRequirements      0.907783   \n",
       "25                http://dbpedia.org/ontology/year      1.000000   \n",
       "26            http://dbpedia.org/ontology/director      1.000000   \n",
       "27                http://dbpedia.org/ontology/year      1.000000   \n",
       "28                http://dbpedia.org/ontology/code      1.000000   \n",
       "29                http://dbpedia.org/ontology/code      1.000000   \n",
       "30               http://dbpedia.org/ontology/genre      1.000000   \n",
       "31   http://dbpedia.org/ontology/computingPlatform      0.782497   \n",
       "32                http://dbpedia.org/ontology/year      1.000000   \n",
       "33           http://dbpedia.org/ontology/developer      1.000000   \n",
       "34               http://dbpedia.org/ontology/genre      1.000000   \n",
       "35   http://dbpedia.org/ontology/computingPlatform      0.782497   \n",
       "36                http://dbpedia.org/ontology/year      1.000000   \n",
       "37           http://dbpedia.org/ontology/developer      1.000000   \n",
       "38               http://dbpedia.org/ontology/genre      1.000000   \n",
       "39   http://dbpedia.org/ontology/computingPlatform      0.782497   \n",
       "40                http://dbpedia.org/ontology/year      1.000000   \n",
       "41           http://dbpedia.org/ontology/developer      1.000000   \n",
       "42               http://dbpedia.org/ontology/genre      1.000000   \n",
       "43   http://dbpedia.org/ontology/computingPlatform      0.782497   \n",
       "44                http://dbpedia.org/ontology/year      1.000000   \n",
       "45                http://dbpedia.org/ontology/year      1.000000   \n",
       "46                                             Nil      0.000000   \n",
       "47            http://dbpedia.org/ontology/director      1.000000   \n",
       "48                http://dbpedia.org/ontology/year      1.000000   \n",
       "49           http://dbpedia.org/ontology/developer      1.000000   \n",
       "50   http://dbpedia.org/ontology/computingPlatform      0.782497   \n",
       "51            http://dbpedia.org/ontology/director      1.000000   \n",
       "52                http://dbpedia.org/ontology/year      1.000000   \n",
       "53                                             Nil      0.000000   \n",
       "54             http://dbpedia.org/ontology/address      1.000000   \n",
       "55            http://dbpedia.org/ontology/director      1.000000   \n",
       "56                http://dbpedia.org/ontology/year      1.000000   \n",
       "57            http://dbpedia.org/ontology/director      1.000000   \n",
       "58                                             Nil      0.000000   \n",
       "59              http://dbpedia.org/ontology/assets      1.000000   \n",
       "\n",
       "                                  SchemaOrgType  SchemaScore  \n",
       "0                                           Nil     0.000000  \n",
       "1                                           Nil     0.000000  \n",
       "2                https://schema.org/releaseDate     1.000000  \n",
       "3                https://schema.org/releaseDate     1.000000  \n",
       "4         http://dbpedia.org/ontology/publisher     1.000000  \n",
       "5           http://dbpedia.org/ontology/address     1.000000  \n",
       "6              https://schema.org/DigitalFormat     0.863042  \n",
       "7                   https://schema.org/currency     1.000000  \n",
       "8                     https://schema.org/height     1.000000  \n",
       "9          http://dbpedia.org/ontology/director     1.000000  \n",
       "10           http://dbpedia.org/ontology/artist     1.000000  \n",
       "11           http://dbpedia.org/ontology/height     1.000000  \n",
       "12            http://dbpedia.org/ontology/state     1.000000  \n",
       "13            http://dbpedia.org/ontology/state     1.000000  \n",
       "14             https://schema.org/copyrightYear     0.848724  \n",
       "15                                          Nil     0.000000  \n",
       "16      http://dbpedia.org/ontology/recordLabel     0.892867  \n",
       "17        http://dbpedia.org/ontology/publisher     1.000000  \n",
       "18             https://schema.org/estimatedCost     0.955836  \n",
       "19                                          Nil     0.000000  \n",
       "20                                          Nil     0.000000  \n",
       "21                                          Nil     0.000000  \n",
       "22        http://dbpedia.org/ontology/publisher     1.000000  \n",
       "23                      https://schema.org/size     1.000000  \n",
       "24  http://dbpedia.org/ontology/operatingSystem     0.902147  \n",
       "25             https://schema.org/copyrightYear     0.848724  \n",
       "26         http://dbpedia.org/ontology/director     1.000000  \n",
       "27             https://schema.org/copyrightYear     0.848724  \n",
       "28                      https://schema.org/Code     1.000000  \n",
       "29                      https://schema.org/Code     1.000000  \n",
       "30            http://dbpedia.org/ontology/genre     1.000000  \n",
       "31         https://schema.org/departurePlatform     0.760722  \n",
       "32             https://schema.org/copyrightYear     0.848724  \n",
       "33                                          Nil     0.000000  \n",
       "34            http://dbpedia.org/ontology/genre     1.000000  \n",
       "35         https://schema.org/departurePlatform     0.760722  \n",
       "36             https://schema.org/copyrightYear     0.848724  \n",
       "37                                          Nil     0.000000  \n",
       "38            http://dbpedia.org/ontology/genre     1.000000  \n",
       "39         https://schema.org/departurePlatform     0.760722  \n",
       "40             https://schema.org/copyrightYear     0.848724  \n",
       "41                                          Nil     0.000000  \n",
       "42            http://dbpedia.org/ontology/genre     1.000000  \n",
       "43         https://schema.org/departurePlatform     0.760722  \n",
       "44             https://schema.org/copyrightYear     0.848724  \n",
       "45             https://schema.org/copyrightYear     0.848724  \n",
       "46                                          Nil     0.000000  \n",
       "47         http://dbpedia.org/ontology/director     1.000000  \n",
       "48             https://schema.org/copyrightYear     0.848724  \n",
       "49                                          Nil     0.000000  \n",
       "50         https://schema.org/departurePlatform     0.760722  \n",
       "51         http://dbpedia.org/ontology/director     1.000000  \n",
       "52             https://schema.org/copyrightYear     0.848724  \n",
       "53                                          Nil     0.000000  \n",
       "54          http://dbpedia.org/ontology/address     1.000000  \n",
       "55         http://dbpedia.org/ontology/director     1.000000  \n",
       "56             https://schema.org/copyrightYear     0.848724  \n",
       "57         http://dbpedia.org/ontology/director     1.000000  \n",
       "58                                          Nil     0.000000  \n",
       "59                                          Nil     0.000000  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def match_with_plural(token, dictionary):\n",
    "    # Attempt direct match first\n",
    "    if token in dictionary:\n",
    "        return dictionary[token]\n",
    "    # Check for 'ies' -> 'y' (families -> family)\n",
    "    if token.endswith('ies') and len(token) > 3:\n",
    "        singular = token[:-3] + 'y'\n",
    "        if singular in dictionary:\n",
    "            return dictionary[singular]\n",
    "    # Check for 'es' -> '' (e.g., classes -> class)\n",
    "    if token.endswith('es') and len(token) > 2:\n",
    "        singular = token[:-2]\n",
    "        if singular in dictionary:\n",
    "            return dictionary[singular]\n",
    "    # Check for 's' -> '' (e.g., chlorides -> chloride)\n",
    "    if token.endswith('s') and len(token) > 2:\n",
    "        singular = token[:-1]\n",
    "        if singular in dictionary:\n",
    "            return dictionary[singular]\n",
    "    return None\n",
    "\n",
    "def apply_analysis(df, target_words_dict, description_words_dict, abbreviations_dict, all_datasets_info):\n",
    "\n",
    "    def get_special_name_format(table_name, column_name):\n",
    "        special_cases = {\n",
    "            'city': 'city',\n",
    "            'country': 'country',\n",
    "            'state': 'state',\n",
    "            'province': 'state'  # province is treated as state\n",
    "        }\n",
    "        \n",
    "        if DB_or_dataset.lower() == 'd':\n",
    "            # For datasets, table_name is a number, so we don't check it\n",
    "            if column_name.lower() == 'name':\n",
    "                return 'name', target_words_dict['name']\n",
    "        else:\n",
    "            # For database tables, check if any special case is in the table name\n",
    "            table_name_str = str(table_name).lower()\n",
    "            for case, format_type in special_cases.items():\n",
    "                if case in table_name_str and column_name.lower() == 'name':\n",
    "                    return f\"{format_type}_name\", target_words_dict[format_type]\n",
    "        \n",
    "        return 'name', target_words_dict['name']\n",
    "    \n",
    "    # main code \n",
    "    # Check if PK/FK information is available\n",
    "    has_pk_fk_info = 'primary_key' in all_datasets_info.columns and 'foreign_keys' in all_datasets_info.columns\n",
    "\n",
    "    # Get primary and foreign keys for each table\n",
    "    pk_fk_dict = {}\n",
    "    if has_pk_fk_info:\n",
    "        for _, row in all_datasets_info.iterrows():\n",
    "            table_name = row['index']\n",
    "            pk = row['primary_key'] if pd.notna(row['primary_key']) else None\n",
    "            fks = row['foreign_keys'].split(', ') if pd.notna(row['foreign_keys']) else []\n",
    "            fk_columns = [fk.split(' -> ')[0] for fk in fks]\n",
    "            pk_fk_dict[table_name] = {'pk': pk, 'fks': fk_columns} \n",
    "\n",
    "    # 'formats_ordered_list' is a list of dictionary keys in the order they appear in 'formats_dictionary'\n",
    "    formats_ordered_list = list(target_words_dict.keys())\n",
    "\n",
    "    # Initialize new columns\n",
    "    df['ColumnKeyword'] = None\n",
    "    df['ColumnFormat'] = None\n",
    "    df['DescriptionKeyword'] = None\n",
    "    df['DescriptionFormat'] = None\n",
    "    count = 0\n",
    "   \n",
    "    # Apply target words analysis\n",
    "    for i, row in df.iterrows():\n",
    "        count += 1\n",
    "        if count % 1000 == 0:\n",
    "            print(f\"✅ Processed {count} rows...\")\n",
    "\n",
    "        std_col_name = row['CleanedColumn']\n",
    "        col_name = row['Column']\n",
    "        table_name = row['dataset_index']\n",
    "\n",
    "        # Skip if 'CleanedColumn' is missing\n",
    "        if pd.isnull(std_col_name):\n",
    "            continue\n",
    "\n",
    "        # Split camel case\n",
    "        std_col_name = split_camel_case(std_col_name)\n",
    "\n",
    "        # Check if the column is a primary key or foreign key\n",
    "        if table_name in pk_fk_dict:\n",
    "            if col_name == pk_fk_dict[table_name]['pk'] or col_name in pk_fk_dict[table_name]['fks']:\n",
    "                df.at[i, 'ColumnKeyword'] = 'id'\n",
    "                df.at[i, 'ColumnFormat'] = 'IDcolumn'\n",
    "                continue\n",
    "\n",
    "        found = False\n",
    "\n",
    "        # Iterate through each word based on the order in 'formats_ordered_list'\n",
    "        for word in formats_ordered_list:\n",
    "            analysis = target_words_dict[word.lower()]\n",
    "            # Special handling for 'name'\n",
    "            if word == 'name':\n",
    "                keyword, format_type = get_special_name_format(table_name, col_name)\n",
    "                if keyword != 'name':\n",
    "                    df.at[i, 'ColumnKeyword'] = keyword\n",
    "                    df.at[i, 'ColumnFormat'] = format_type\n",
    "                    found = True\n",
    "                    break\n",
    "                pattern = rf'({word})(?![\\\\w-])'\n",
    "            # Special handling for uppercase 'ID' at the end of a column name\n",
    "            elif word == 'id' and col_name.endswith('ID'):\n",
    "                df.at[i, 'ColumnKeyword'] = 'id'\n",
    "                df.at[i, 'ColumnFormat'] = target_words_dict.get('id', 'ID column')\n",
    "                found = True\n",
    "                break\n",
    "            else:\n",
    "                # General matching for other terms\n",
    "                pattern = rf'\\b{word}\\b'\n",
    "\n",
    "            # Search for the pattern in the CleanedColumn\n",
    "            if re.search(pattern, std_col_name, re.IGNORECASE):\n",
    "                df.at[i, 'ColumnKeyword'] = word\n",
    "                df.at[i, 'ColumnFormat'] = analysis\n",
    "                found = True\n",
    "                break\n",
    "\n",
    "        # If no match found, replace abbreviations and try again\n",
    "        if not found:\n",
    "            replaced_text = replace_abbreviations(std_col_name, abbreviations_dict)\n",
    "            for word in formats_ordered_list:\n",
    "                pattern = rf'\\b{word}\\b'\n",
    "                if re.search(pattern, replaced_text, re.IGNORECASE):\n",
    "                    df.at[i, 'ColumnKeyword'] = word\n",
    "                    df.at[i, 'ColumnFormat'] = target_words_dict[word.lower()]\n",
    "                    found = True\n",
    "                    break\n",
    "\n",
    "\n",
    "        # If still no match, check tokens only\n",
    "        if not found:\n",
    "            tokens = re.findall(r'\\b\\w+\\b|%', row['CleanedColumn'].lower())\n",
    "            for token in tokens:\n",
    "                expanded_token = abbreviations_dict.get(token.lower(), None)\n",
    "                # First check plural support for expanded_token\n",
    "                if expanded_token:\n",
    "                    match = match_with_plural(expanded_token, target_words_dict)\n",
    "                    if match:\n",
    "                        df.at[i, 'ColumnKeyword'] = expanded_token\n",
    "                        df.at[i, 'ColumnFormat'] = match\n",
    "                        found = True\n",
    "                        break\n",
    "                # Then check plural support for the token itself\n",
    "                match = match_with_plural(token, target_words_dict)\n",
    "                if match:\n",
    "                    df.at[i, 'ColumnKeyword'] = token\n",
    "                    df.at[i, 'ColumnFormat'] = match\n",
    "                    found = True\n",
    "                    break\n",
    "\n",
    "        # -- PRIORITIZE percentage if % present in CleanedColumn tokens --\n",
    "        tokens = re.findall(r'\\b\\w+\\b|%', row['CleanedColumn'].lower())\n",
    "        if '%' in tokens and '%' in target_words_dict:\n",
    "            df.at[i, 'ColumnKeyword'] = '%'\n",
    "            df.at[i, 'ColumnFormat'] = target_words_dict['%']\n",
    "\n",
    "    count = 0\n",
    "    # Apply description words analysis\n",
    "    for i, row in df.iterrows():\n",
    "        count += 1\n",
    "        if count % 1000 == 0:\n",
    "            print(f\"✅ Processed {count} rows...\")\n",
    "        # Skip if 'Description' is missing\n",
    "        if pd.isnull(row['Description']):\n",
    "            continue\n",
    "        for word, analysis in description_words_dict.items():\n",
    "            if word in ['is', 'has']:\n",
    "                pattern = r'^\\s*' + re.escape(word) + r'\\b'\n",
    "                if re.search(pattern, row['Description'], re.IGNORECASE):\n",
    "                    df.at[i, 'DescriptionKeyword'] = word\n",
    "                    df.at[i, 'DescriptionFormat'] = analysis\n",
    "                    break\n",
    "            else:\n",
    "                if re.search(rf'\\b{re.escape(word)}\\b', row['Description'], re.IGNORECASE):\n",
    "                    df.at[i, 'DescriptionKeyword'] = word\n",
    "                    df.at[i, 'DescriptionFormat'] = analysis\n",
    "                    break\n",
    "                elif not word.isalnum():\n",
    "                    if word.lower() in row['Description'].lower():\n",
    "                        df.at[i, 'DescriptionKeyword'] = word\n",
    "                        df.at[i, 'DescriptionFormat'] = analysis\n",
    "                        break\n",
    "\n",
    "    return df\n",
    "\n",
    "# Apply this function to the dataframe\n",
    "analysed_columns_df = apply_analysis(preprocessed_columns_df.copy(), target_words_dict, description_words_dict, abbreviations_dict, datasets_xlsx)\n",
    "\n",
    "\n",
    "def match_with_ontology(\n",
    "    header, labels_list, label_to_id, embeddings_dict,\n",
    "    syntactic_thresh=0.9, semantic_thresh=0.7, column_keyword=None\n",
    "):\n",
    "    header_lc = header.lower().strip()\n",
    "\n",
    "    # 1. Syntactic (exact) match\n",
    "    match_id = syntactic_match(header_lc, labels_list, label_to_id, threshold=syntactic_thresh)\n",
    "    if match_id:\n",
    "        return match_id, 1.0\n",
    "\n",
    "    # 2. Substring preference (force this to happen BEFORE semantic!)\n",
    "    substr_matches = [label for label in labels_list if label in header_lc and len(label) >= 4]\n",
    "    if substr_matches:\n",
    "        substr_matches = sorted(\n",
    "            substr_matches,\n",
    "            key=lambda x: (len(x.split()), len(x)),  # more words, then longer\n",
    "            reverse=True\n",
    "        )\n",
    "        best_label = substr_matches[0]\n",
    "        print(f\"[Substring wins] '{best_label}' in '{header}'\")\n",
    "        return label_to_id[best_label], 1.0\n",
    "\n",
    "    # 3. Semantic match\n",
    "    match_id, sim_score = semantic_match(header_lc, labels_list, label_to_id, embeddings_dict, similarity_threshold=semantic_thresh)\n",
    "    if match_id:\n",
    "        return match_id, sim_score\n",
    "\n",
    "    # 4. ColumnKeyword\n",
    "    if column_keyword:\n",
    "        ck = column_keyword.lower().strip()\n",
    "        match_id = syntactic_match(ck, labels_list, label_to_id, threshold=syntactic_thresh)\n",
    "        if match_id:\n",
    "            return match_id, 1.0\n",
    "        match_id, sim_score_ck = semantic_match(ck, labels_list, label_to_id, embeddings_dict, similarity_threshold=semantic_thresh)\n",
    "        if match_id:\n",
    "            return match_id, sim_score_ck\n",
    "\n",
    "    return \"Nil\", 0.0\n",
    "\n",
    "\n",
    "def annotate_all_kgs(df, syntactic_thresh=0.9, semantic_thresh=0.75):\n",
    "    def kg_annotate_row(row, labels_list, label_to_id, embeddings_dict):\n",
    "        return match_with_ontology(\n",
    "            str(row['CleanedColumn']),\n",
    "            labels_list, label_to_id, embeddings_dict,\n",
    "            syntactic_thresh, semantic_thresh,\n",
    "            column_keyword=row.get('ColumnKeyword', None)\n",
    "        )\n",
    "\n",
    "    db_results = df.apply(\n",
    "        lambda row: kg_annotate_row(row, dbpedia_labels, dbpedia_label_to_id, dbpedia_embeddings),\n",
    "        axis=1\n",
    "    )\n",
    "    df['DBpediaType'] = [r[0] for r in db_results]\n",
    "    df['DBpediaScore'] = [r[1] for r in db_results]\n",
    "\n",
    "    schema_results = df.apply(\n",
    "        lambda row: kg_annotate_row(row, schema_labels, schema_label_to_id, schema_embeddings),\n",
    "        axis=1\n",
    "    )\n",
    "    df['SchemaOrgType'] = [r[0] for r in schema_results]\n",
    "    df['SchemaScore'] = [r[1] for r in schema_results]\n",
    "\n",
    "    return df\n",
    "\n",
    "def get_top_k_ontology_matches(header, labels_list, label_to_id, embeddings_dict, k=5):\n",
    "    header_lc = header.lower().strip()\n",
    "    candidates = []\n",
    "\n",
    "    # Syntactic (exact) match\n",
    "    match_id = syntactic_match(header_lc, labels_list, label_to_id, threshold=0.9)\n",
    "    if match_id:\n",
    "        candidates.append((match_id, 1.0, 'syntactic'))\n",
    "\n",
    "    # Semantic matches (top K by cosine)\n",
    "    header_emb = get_embedding(header_lc)\n",
    "    all_scores = []\n",
    "    for label in labels_list:\n",
    "        emb = embeddings_dict[label]\n",
    "        score = np.dot(header_emb, emb) / (np.linalg.norm(header_emb) * np.linalg.norm(emb) + 1e-8)\n",
    "        all_scores.append((label_to_id[label], score, 'semantic'))\n",
    "    # Sort and take top k (not already present)\n",
    "    top_sem = sorted(all_scores, key=lambda x: x[1], reverse=True)\n",
    "    for uri, score, method in top_sem:\n",
    "        if uri not in [c[0] for c in candidates]:\n",
    "            candidates.append((uri, score, method))\n",
    "        if len(candidates) >= k:\n",
    "            break\n",
    "\n",
    "    # Substring matches (if not already present)\n",
    "    substr_matches = [label for label in labels_list if label in header_lc]\n",
    "    for label in substr_matches:\n",
    "        uri = label_to_id[label]\n",
    "        if uri not in [c[0] for c in candidates]:\n",
    "            candidates.append((uri, 0.98, 'substring'))\n",
    "        if len(candidates) >= k:\n",
    "            break\n",
    "\n",
    "    # Only keep the first k, sorted by score (descending)\n",
    "    candidates = sorted(candidates, key=lambda x: x[1], reverse=True)[:k]\n",
    "    return candidates\n",
    "\n",
    "\n",
    "analysed_columns_df['ColumnDescCombined'] = (\n",
    "    analysed_columns_df['CleanedColumn'].fillna('').astype(str) + ' ' +\n",
    "    analysed_columns_df['Description'].fillna('').astype(str)\n",
    ")\n",
    "\n",
    "analysed_columns_df = annotate_all_kgs(analysed_columns_df, syntactic_thresh=1.0)\n",
    "\n",
    "analysed_columns_df['DBpediaTop5'] = analysed_columns_df['CleanedColumn'].apply(\n",
    "    lambda x: get_top_k_ontology_matches(\n",
    "        str(x), dbpedia_labels, dbpedia_label_to_id, dbpedia_embeddings, k=5\n",
    "    )\n",
    ")\n",
    "\n",
    "# Preview results\n",
    "ac = analysed_columns_df[['CleanedColumn', 'Description', 'DBpediaType', 'DBpediaScore', 'SchemaOrgType', 'SchemaScore']].head(60)\n",
    "\n",
    "print(f\"Last run on: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "\n",
    "ac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['release date', 'date']\n"
     ]
    }
   ],
   "source": [
    "header = \"au release date\"\n",
    "matches = [label for label in dbpedia_labels if (label in header or header in label) and len(label) >= 4]\n",
    "matches = sorted(matches, key=lambda x: (len(x.split()), len(x)), reverse=True)\n",
    "print(matches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FinalFormat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last run on: 2025-11-07 21:49:54\n"
     ]
    }
   ],
   "source": [
    "def analysis_of_column(ColumnFormat, DescriptionFormat, DescriptionKeyword, index_value):\n",
    "    if ColumnFormat is None and DescriptionFormat is None:\n",
    "        return 'NaN'\n",
    "\n",
    "    # If either is 'None', choose the one that has a value\n",
    "    if pd.isnull(ColumnFormat):\n",
    "        return DescriptionFormat\n",
    "    elif pd.isnull(DescriptionFormat):\n",
    "        return ColumnFormat\n",
    "  \n",
    "    # Prioritize 'categorical' over 'numerical', but prefer specific numeric types in DescriptionKeyword\n",
    "    if ColumnFormat == 'categorical' and DescriptionFormat == 'numerical':\n",
    "        if DescriptionKeyword in ['float', 'double']:\n",
    "            return DescriptionFormat\n",
    "        return ColumnFormat\n",
    "    \n",
    "    # If one is 'string' and the other is not, choose the one that is not 'string'\n",
    "    if ColumnFormat == 'string' and DescriptionFormat not in [None, 'string', 'NaN']:\n",
    "        return DescriptionFormat\n",
    "    elif DescriptionFormat == 'string' and ColumnFormat not in [None, 'string', 'NaN']:\n",
    "        return ColumnFormat\n",
    "\n",
    "    # If one is 'hour' and the other is numerical, choose numerical'\n",
    "    if ColumnFormat == 'hour' and DescriptionFormat.startswith(\"numerical\"):\n",
    "        return DescriptionFormat\n",
    "    elif DescriptionFormat == 'hour' and ColumnFormat.startswith(\"numerical\"):\n",
    "        return ColumnFormat\n",
    "    \n",
    "    # Datetime should always win\n",
    "    if ColumnFormat == 'datetime' or DescriptionFormat == 'datetime':\n",
    "        return 'datetime'\n",
    "\n",
    "    # ID column should always win\n",
    "    if ColumnFormat == \"IDcolumn\" or DescriptionFormat == \"IDcolumn\":\n",
    "        return \"IDcolumn\"\n",
    "    \n",
    "    # percentage should always win\n",
    "    if ColumnFormat == \"percentage\" or DescriptionFormat == \"percentage\":\n",
    "        return \"percentage\"\n",
    "    \n",
    "    # binary should always win\n",
    "    if ColumnFormat == 'binary' or DescriptionFormat == 'binary':\n",
    "        return 'binary' \n",
    "\n",
    "    # If both are 'numerical' or if ColumnFormat is in the predefined list, return ColumnFormat\n",
    "    if (ColumnFormat.startswith(\"numerical\") and DescriptionFormat.startswith(\"numerical\")) or \\\n",
    "       ColumnFormat in [\"phone\", \"month\", \"date\", \"weekday\", \"week\", \"year\",\n",
    "                        \"country\", \"state\", \"city\", \"street\", \"name\",\n",
    "                        \"latitude\", \"longitude\", \"postalcode\", \"URLformat\",\"IPformat\", \n",
    "                        \"E-mailformat\", \"binary\"]:\n",
    "        return ColumnFormat\n",
    "    elif ColumnFormat in [\"age\"] and DescriptionFormat not in ['categorical']:\n",
    "        return ColumnFormat\n",
    "    # If no exceptions apply, return the value from \"DescriptionFormat\"\n",
    "    else:\n",
    "        return DescriptionFormat\n",
    "\n",
    "# Apply the function to create the new column\n",
    "analysed_columns_df['FinalFormat'] = analysed_columns_df.apply(\n",
    "    lambda row: analysis_of_column(\n",
    "        row['ColumnFormat'],\n",
    "        row['DescriptionFormat'],\n",
    "        row['DescriptionKeyword'],\n",
    "        row['dataset_index']),  \n",
    "    axis=1\n",
    ")\n",
    "print(f\"Last run on: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identify Origin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last run on: 2025-11-07 21:49:54\n"
     ]
    }
   ],
   "source": [
    "def identify_origin(row):\n",
    "    analysis_col = row['FinalFormat']\n",
    "    ColumnFormat = row['ColumnFormat']\n",
    "    DescriptionFormat = row['DescriptionFormat']\n",
    "\n",
    "    # Check if the value in 'FinalFormat' came from 'ColumnFormat'\n",
    "    if pd.notnull(ColumnFormat) and analysis_col == ColumnFormat:\n",
    "        return row['ColumnKeyword']\n",
    "\n",
    "    # Check if the value in 'FinalFormat' came from 'DescriptionFormat'\n",
    "    elif pd.notnull(DescriptionFormat) and analysis_col == DescriptionFormat:\n",
    "        return row['DescriptionKeyword']\n",
    "\n",
    "    # If none of the above conditions are met, return NaN or any default value you prefer\n",
    "    else:\n",
    "        return 'NaN'\n",
    "\n",
    "# Create the new column 'SourceKeyword' in analysed_columns_df\n",
    "analysed_columns_df['SourceKeyword'] = analysed_columns_df.apply(identify_origin, axis=1)\n",
    "print(f\"Last run on: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last run on: 2025-11-07 21:49:54\n"
     ]
    }
   ],
   "source": [
    "# Save the results to a new Excel file\n",
    "analysed_columns_df.to_excel(analysed_columns_file_path, index=False)\n",
    "\n",
    "from datetime import datetime\n",
    "print(f\"Last run on: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SemTab 2024 Metadata only track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results written to dbpedia_match_results.xlsx\n",
      "Last run on: 2025-11-07 21:49:54\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "# === 1. Read your result/output file and GT file ===\n",
    "results_df = pd.read_excel('AnalysedColumnsSemTabTest2024.xlsx')\n",
    "gt_df = pd.read_excel('r1_test_metadata_GT.xlsx', header=None)\n",
    "\n",
    "# === 2. Helper to get column content after number+dot, preserving everything else ===\n",
    "def extract_col_after_number(s):\n",
    "    s = str(s)\n",
    "    if '.' in s:\n",
    "        return s.split('.', 1)[1].lstrip()  # Only removes leading space after the dot\n",
    "    return s\n",
    "\n",
    "# === 3. Build GT map: {column_name as in GT : dbpedia uri} ===\n",
    "gt_map = {}\n",
    "for i, row in gt_df.iterrows():\n",
    "    gt_col_name = str(row[2]).strip('\\n\\r')  # Only strip newlines, not spaces or dots\n",
    "    gt_dbpedia = str(row[1]).strip()\n",
    "    gt_map[gt_col_name] = gt_dbpedia\n",
    "\n",
    "# === 4. Main matching and output rows ===\n",
    "excel_rows = []\n",
    "top1_correct = 0\n",
    "top5_correct = 0\n",
    "total = 0\n",
    "\n",
    "for i, row in results_df.iterrows():\n",
    "    orig_col = str(row['Original Column'])\n",
    "    col_key = extract_col_after_number(orig_col)\n",
    "\n",
    "    gt_uri = gt_map.get(col_key, None)\n",
    "\n",
    "    if gt_uri is None or gt_uri.lower() in ('', 'nan'):\n",
    "        result = {\n",
    "            \"Original Column\": orig_col,\n",
    "            \"Cleaned Column\": col_key,\n",
    "            \"GT DBpediaType\": None,\n",
    "            \"Model DBpediaType\": row['DBpediaType'],\n",
    "            \"Model DBpediaTop5\": None,\n",
    "            \"Top1?\": False,\n",
    "            \"Top5?\": False\n",
    "        }\n",
    "        excel_rows.append(result)\n",
    "        continue\n",
    "\n",
    "    total += 1\n",
    "    # Top 1\n",
    "    model_top1 = str(row['DBpediaType']).strip()\n",
    "    top1 = model_top1 == gt_uri\n",
    "\n",
    "    # Top 5\n",
    "    found_top5 = False\n",
    "    top5_uris = []\n",
    "    top5_str = str(row['DBpediaTop5'])\n",
    "    try:\n",
    "        top5_list = ast.literal_eval(top5_str) if top5_str not in ('', 'nan', 'None') else []\n",
    "        top5_uris = [entry[0] if isinstance(entry, (list, tuple)) else entry for entry in top5_list]\n",
    "        if gt_uri in top5_uris:\n",
    "            found_top5 = True\n",
    "    except Exception as e:\n",
    "        pass\n",
    "\n",
    "    if top1: top1_correct += 1\n",
    "    if found_top5: top5_correct += 1\n",
    "\n",
    "    # Record row for Excel\n",
    "    excel_rows.append({\n",
    "        \"Original Column\": orig_col,\n",
    "        \"Cleaned Column\": col_key,\n",
    "        \"GT DBpediaType\": gt_uri,\n",
    "        \"Model DBpediaType\": model_top1,\n",
    "        \"Model DBpediaTop5\": top5_uris,\n",
    "        \"Top1?\": top1,\n",
    "        \"Top5?\": found_top5\n",
    "    })\n",
    "\n",
    "# === 5. Add summary row ===\n",
    "output_df = pd.DataFrame(excel_rows)\n",
    "summary_row = {\n",
    "    \"Original Column\": \"SUMMARY\",\n",
    "    \"GT DBpediaType\": f\"Top1: {top1_correct}/{total} ({top1_correct/total:.2%})\",\n",
    "    \"Model DBpediaType\": f\"Top5: {top5_correct}/{total} ({top5_correct/total:.2%})\"\n",
    "}\n",
    "output_df = pd.concat([output_df, pd.DataFrame([summary_row])], ignore_index=True)\n",
    "\n",
    "# === 6. Write to Excel, NO extra Excel libraries required ===\n",
    "output_xlsx = 'dbpedia_match_results.xlsx'\n",
    "output_df.to_excel(output_xlsx, index=False)\n",
    "\n",
    "print(f\"Results written to {output_xlsx}\")\n",
    "\n",
    "# ========== END OF SCRIPT ==========\n",
    "print(f\"Last run on: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
