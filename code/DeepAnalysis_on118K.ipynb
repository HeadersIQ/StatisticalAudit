{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb40262c",
   "metadata": {},
   "source": [
    "KaggleViznet_95CI_StatAudit_UniverseAndSample.xlsx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a5a4839d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows in file: 118639\n",
      "Universe (FinalFormat not NaN): 102205\n",
      "Strict trivial (Cleaned single token + orig word or numeric-only): 53763\n",
      "trivial_single_token but original multi-token (non-trivial): 1492\n",
      "Non-trivial rows for sampling: 48442\n",
      "Raw stratified sample size (before coverage correction): 2288\n",
      "Final sample size (after coverage correction): 2295\n",
      "Rows added by coverage correction: 7\n",
      "Formats added by coverage correction:\n",
      "postalcode, normalized, acidity, modelname, ph, alkalinity, saltness\n",
      "\n",
      "Results written to: KaggleViznet_95CI_StatAudit_UniverseAndSample.xlsx\n",
      "Last run on: 2025-12-15 13:51:59\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 1. Clean VizNet-style names in column \"name\"\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "def clean_viznet_name(raw_name: object) -> object:\n",
    "    \"\"\"\n",
    "    Normalise VizNet / SATO names such as:\n",
    "      0_1438...json.gz_481-APC USB cable schematic pi_ZFCQZC7DYMRKS2PV\n",
    "\n",
    "    Keep only the useful part between '.gz_' and the last '_CODE', and\n",
    "    also strip trailing '(CODE)' patterns.\n",
    "\n",
    "    Examples:\n",
    "      \"0_...json.gz_481-APC USB cable schematic pi_ZFCQZC7DYMRKS2PV\"\n",
    "        -> \"481-APC USB cable schematic pi\"\n",
    "\n",
    "      \"iTunes - Music - Cosmic L (TQWNRUTARQEBIXOH)\"\n",
    "        -> \"iTunes - Music - Cosmic L\"\n",
    "    \"\"\"\n",
    "    if not isinstance(raw_name, str):\n",
    "        return raw_name\n",
    "\n",
    "    name = raw_name.strip()\n",
    "\n",
    "    # Case 1 - CC-MAIN pattern with \".gz_####-Title_CODE\"\n",
    "    m = re.search(r\"\\.gz_(\\d+)-(.+)\", name)\n",
    "    if m:\n",
    "        num = m.group(1)\n",
    "        rest = m.group(2)\n",
    "\n",
    "        # Remove final underscore code (e.g. _ZFCQZC7DYMRKS2PV)\n",
    "        rest = re.sub(r\"_[A-Z0-9]{10,}$\", \"\", rest).strip()\n",
    "        cleaned = f\"{num}-{rest}\"\n",
    "    else:\n",
    "        cleaned = name\n",
    "\n",
    "    # Case 2 - remove trailing \"(CODE)\" used in some titles\n",
    "    cleaned = re.sub(r\"\\s*\\([A-Z0-9]{10,}\\)\\s*$\", \"\", cleaned).strip()\n",
    "\n",
    "    return cleaned\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 2. Abbreviation usage\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "def compute_abbrev_used(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Create boolean column 'abbrev_used' based on any non-null\n",
    "    abbreviation-log columns present in the DataFrame:\n",
    "      - abbrev_clean\n",
    "      - abbrev_desc\n",
    "      - abbrev_clean_analysis\n",
    "    \"\"\"\n",
    "    abbrev_cols = [\n",
    "        col for col in [\"abbrev_clean\", \"abbrev_desc\", \"abbrev_clean_analysis\"]\n",
    "        if col in df.columns\n",
    "    ]\n",
    "\n",
    "    if abbrev_cols:\n",
    "        df[\"abbrev_used\"] = df[abbrev_cols].notna().any(axis=1)\n",
    "    else:\n",
    "        df[\"abbrev_used\"] = False\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 3. Original token statistics (now with numeric-only flag)\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "def add_original_token_stats(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Analyse the ORIGINAL column header (column 'Original Column') and compute:\n",
    "\n",
    "      - orig_token_count: number of alphabetic tokens after removing the\n",
    "        numeric prefix \"NN.\".\n",
    "      - orig_single_token: True when there is exactly one alphabetic token.\n",
    "      - orig_zero_token: True when there are no alphabetic tokens at all\n",
    "        (years like 2003, 1991/92, symbols like %, #, 1977.0, etc).\n",
    "      - orig_numeric_only: True when the tail has at least one digit and\n",
    "        no letters (pure numeric labels such as 2003, 1977.0, 1991/92).\n",
    "\n",
    "    This separates:\n",
    "      - well-formed word headers,\n",
    "      - numeric-only headers, and\n",
    "      - symbol-only or mixed headers.\n",
    "    \"\"\"\n",
    "\n",
    "    def analyse_original(original: object):\n",
    "        if not isinstance(original, str):\n",
    "            return 0, False, False, False\n",
    "\n",
    "        # Remove leading \"NN.\" or \"NN.   \"\n",
    "        m = re.match(r\"\\s*\\d+\\.\\s*(.*)\", original)\n",
    "        tail = m.group(1) if m else original\n",
    "\n",
    "        # Alphabetic tokens for orig_token_count\n",
    "        letter_tokens = re.findall(r\"[A-Za-z]+\", tail)\n",
    "        token_count = len(letter_tokens)\n",
    "\n",
    "        has_alpha = bool(re.search(r\"[A-Za-z]\", tail))\n",
    "        has_digit = bool(re.search(r\"\\d\", tail))\n",
    "\n",
    "        orig_single = token_count == 1\n",
    "        orig_zero = token_count == 0\n",
    "        # numeric-only: at least one digit and no letters\n",
    "        orig_numeric_only = has_digit and (not has_alpha)\n",
    "\n",
    "        return token_count, orig_single, orig_zero, orig_numeric_only\n",
    "\n",
    "    analysed = df[\"Original Column\"].apply(analyse_original)\n",
    "\n",
    "    df[\"orig_token_count\"] = analysed.apply(lambda t: t[0])\n",
    "    df[\"orig_single_token\"] = analysed.apply(lambda t: t[1])\n",
    "    df[\"orig_zero_token\"] = analysed.apply(lambda t: t[2])\n",
    "    df[\"orig_numeric_only\"] = analysed.apply(lambda t: t[3])\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 4. Trivial single-token detection on CleanedColumn\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "def is_trivial_single_token(row: pd.Series) -> bool:\n",
    "    \"\"\"\n",
    "    Mark row as trivial_single_token when:\n",
    "\n",
    "      - CleanedColumn has exactly 1 token;\n",
    "      - no abbreviation was used;\n",
    "      - CleanedColumn, SourceKeyword and ColumnKeyword are identical\n",
    "        (case-insensitive);\n",
    "      - FinalFormat equals ColumnFormat.\n",
    "\n",
    "    Typical examples:\n",
    "      3. Name  -> name\n",
    "      2. Type  -> categorical\n",
    "      1. ID    -> IDcolumn\n",
    "\n",
    "    Note: this is based on the cleaned header, not on the original text.\n",
    "          We separately track whether the original header had a single\n",
    "          token (orig_single_token) and whether it was numeric-only\n",
    "          (orig_numeric_only).\n",
    "    \"\"\"\n",
    "    cleaned = str(row.get(\"CleanedColumn\", \"\")).strip()\n",
    "    if not cleaned or pd.isna(row.get(\"FinalFormat\")):\n",
    "        return False\n",
    "\n",
    "    tokens = cleaned.split()\n",
    "    if len(tokens) != 1:\n",
    "        return False\n",
    "\n",
    "    cleaned_l = cleaned.lower()\n",
    "\n",
    "    source_kw = (\n",
    "        str(row.get(\"SourceKeyword\", \"\")).strip().lower()\n",
    "        if pd.notna(row.get(\"SourceKeyword\"))\n",
    "        else \"\"\n",
    "    )\n",
    "    col_kw = (\n",
    "        str(row.get(\"ColumnKeyword\", \"\")).strip().lower()\n",
    "        if pd.notna(row.get(\"ColumnKeyword\"))\n",
    "        else \"\"\n",
    "    )\n",
    "\n",
    "    ff = row.get(\"FinalFormat\")\n",
    "    col_fmt = row.get(\"ColumnFormat\")\n",
    "\n",
    "    abbrev_used = bool(row.get(\"abbrev_used\", False))\n",
    "    if abbrev_used:\n",
    "        return False\n",
    "\n",
    "    cond_keywords = bool(source_kw) and bool(col_kw) and (\n",
    "        cleaned_l == source_kw == col_kw\n",
    "    )\n",
    "    cond_formats = pd.notna(ff) and pd.notna(col_fmt) and (str(ff) == str(col_fmt))\n",
    "\n",
    "    return cond_keywords and cond_formats\n",
    "\n",
    "\n",
    "def add_trivial_flag(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Add boolean column 'trivial_single_token' to the DataFrame\n",
    "    based on CleanedColumn and the rules in is_trivial_single_token.\n",
    "    \"\"\"\n",
    "    df[\"trivial_single_token\"] = df.apply(is_trivial_single_token, axis=1)\n",
    "    return df\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 5. Sample size for finite population\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "def compute_sample_size(\n",
    "    N: int,\n",
    "    z: float = 1.96,\n",
    "    e: float = 0.02,\n",
    "    p: float = 0.5\n",
    ") -> int:\n",
    "    \"\"\"\n",
    "    Finite population sample size for a proportion with\n",
    "    confidence level z, margin of error e, and true proportion p.\n",
    "    \"\"\"\n",
    "    if N <= 0:\n",
    "        return 0\n",
    "\n",
    "    n0 = (z ** 2) * p * (1 - p) / (e ** 2)\n",
    "    n = (N * n0) / (N + n0 - 1)\n",
    "    return int(round(n))\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 6. Stratified sampling by area + abbrev_used (non-trivial)\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "def build_stratified_sample_by_area_abbrev(\n",
    "    df_nontrivial: pd.DataFrame,\n",
    "    random_state: int = 42,\n",
    "    z: float = 1.96,\n",
    "    e: float = 0.02,\n",
    "    p: float = 0.5,\n",
    "):\n",
    "    \"\"\"\n",
    "    Given the non-trivial universe:\n",
    "\n",
    "      - Build stratum = \"area_with_abbrev\" or \"area_no_abbrev\".\n",
    "      - Compute total sample size at 95 percent confidence and 2 percent error.\n",
    "      - Allocate sample size proportionally across strata.\n",
    "      - Return:\n",
    "          sample_df   -> concatenated stratified sample\n",
    "          strata_info -> population and sample counts per stratum\n",
    "    \"\"\"\n",
    "    df = df_nontrivial.copy()\n",
    "\n",
    "    N = len(df)\n",
    "    if N == 0:\n",
    "        raise ValueError(\"No non-trivial rows available for sampling.\")\n",
    "\n",
    "    n_total = compute_sample_size(N, z=z, e=e, p=p)\n",
    "\n",
    "    df[\"stratum\"] = df[\"area\"].astype(str) + \"_\" + df[\"abbrev_used\"].map(\n",
    "        {True: \"with_abbrev\", False: \"no_abbrev\"}\n",
    "    )\n",
    "\n",
    "    strata_pop = (\n",
    "        df.groupby(\"stratum\")\n",
    "        .size()\n",
    "        .rename(\"population_n\")\n",
    "        .reset_index()\n",
    "        .sort_values(\"population_n\", ascending=False)\n",
    "    )\n",
    "\n",
    "    strata_pop[\"sample_n\"] = (\n",
    "        strata_pop[\"population_n\"] * n_total / N\n",
    "    ).round().astype(int)\n",
    "\n",
    "    # ensure at least 1 sample per non-empty stratum\n",
    "    mask_zero = (strata_pop[\"population_n\"] > 0) & (strata_pop[\"sample_n\"] == 0)\n",
    "    strata_pop.loc[mask_zero, \"sample_n\"] = 1\n",
    "\n",
    "    # adjust rounding to match total n_total\n",
    "    diff = n_total - strata_pop[\"sample_n\"].sum()\n",
    "    while diff != 0 and len(strata_pop) > 0:\n",
    "        if diff > 0:\n",
    "            idx = strata_pop[\"population_n\"].idxmax()\n",
    "            strata_pop.at[idx, \"sample_n\"] += 1\n",
    "            diff -= 1\n",
    "        else:\n",
    "            mask_can_reduce = strata_pop[\"sample_n\"] > 1\n",
    "            if not mask_can_reduce.any():\n",
    "                break\n",
    "            idx = strata_pop.loc[mask_can_reduce, \"population_n\"].idxmax()\n",
    "            strata_pop.at[idx, \"sample_n\"] -= 1\n",
    "            diff += 1\n",
    "\n",
    "    samples = []\n",
    "    for _, row in strata_pop.iterrows():\n",
    "        stratum = row[\"stratum\"]\n",
    "        k = int(row[\"sample_n\"])\n",
    "        sub = df[df[\"stratum\"] == stratum]\n",
    "\n",
    "        if k >= len(sub):\n",
    "            samp = sub.copy()\n",
    "        else:\n",
    "            samp = sub.sample(n=k, random_state=random_state)\n",
    "\n",
    "        samples.append(samp)\n",
    "\n",
    "    sample_df = pd.concat(samples).sort_index()\n",
    "\n",
    "    return sample_df, strata_pop\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 7. Area-level summary\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "def build_area_summary(\n",
    "    df_nontrivial: pd.DataFrame,\n",
    "    sample_df: pd.DataFrame,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Build an area-level table with:\n",
    "\n",
    "      - area_population_n\n",
    "      - area_sample_n\n",
    "      - pop_abbrev_true / pop_abbrev_false\n",
    "      - sample_abbrev_true / sample_abbrev_false\n",
    "    \"\"\"\n",
    "    pop_area = (\n",
    "        df_nontrivial.groupby(\"area\")\n",
    "        .agg(\n",
    "            area_population_n=(\"area\", \"size\"),\n",
    "            pop_abbrev_true=(\"abbrev_used\", lambda x: int(x.sum())),\n",
    "            pop_abbrev_false=(\"abbrev_used\", lambda x: int((~x).sum())),\n",
    "        )\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    samp_area = (\n",
    "        sample_df.groupby(\"area\")\n",
    "        .agg(\n",
    "            area_sample_n=(\"area\", \"size\"),\n",
    "            sample_abbrev_true=(\"abbrev_used\", lambda x: int(x.sum())),\n",
    "            sample_abbrev_false=(\"abbrev_used\", lambda x: int((~x).sum())),\n",
    "        )\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    area_summary = pop_area.merge(samp_area, on=\"area\", how=\"left\").fillna(0)\n",
    "\n",
    "    int_cols = [\n",
    "        \"area_population_n\",\n",
    "        \"pop_abbrev_true\",\n",
    "        \"pop_abbrev_false\",\n",
    "        \"area_sample_n\",\n",
    "        \"sample_abbrev_true\",\n",
    "        \"sample_abbrev_false\",\n",
    "    ]\n",
    "    area_summary[int_cols] = area_summary[int_cols].astype(int)\n",
    "\n",
    "    return area_summary\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 8A. Formats summary (population vs sample)\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "def build_formats_summary(\n",
    "    df_nontrivial: pd.DataFrame,\n",
    "    sample_df: pd.DataFrame,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Build a FinalFormat-level table with both population and sample distributions.\n",
    "\n",
    "    Output columns:\n",
    "      - FinalFormat\n",
    "      - population_n\n",
    "      - population_percent\n",
    "      - sample_n\n",
    "      - sample_percent\n",
    "      - percent_diff (sample_percent - population_percent)\n",
    "\n",
    "    Notes:\n",
    "      - Percent columns are in percentage points (0-100), not proportions.\n",
    "      - Missing formats in either side are filled with 0.\n",
    "    \"\"\"\n",
    "    pop_total = int(len(df_nontrivial))\n",
    "    samp_total = int(len(sample_df))\n",
    "\n",
    "    pop_counts = (\n",
    "        df_nontrivial[\"FinalFormat\"]\n",
    "        .dropna()\n",
    "        .astype(str)\n",
    "        .value_counts()\n",
    "        .rename(\"population_n\")\n",
    "        .reset_index()\n",
    "        .rename(columns={\"index\": \"FinalFormat\"})\n",
    "    )\n",
    "\n",
    "    samp_counts = (\n",
    "        sample_df[\"FinalFormat\"]\n",
    "        .dropna()\n",
    "        .astype(str)\n",
    "        .value_counts()\n",
    "        .rename(\"sample_n\")\n",
    "        .reset_index()\n",
    "        .rename(columns={\"index\": \"FinalFormat\"})\n",
    "    )\n",
    "\n",
    "    summary = pop_counts.merge(samp_counts, on=\"FinalFormat\", how=\"outer\").fillna(0)\n",
    "\n",
    "    summary[\"population_n\"] = summary[\"population_n\"].astype(int)\n",
    "    summary[\"sample_n\"] = summary[\"sample_n\"].astype(int)\n",
    "\n",
    "    summary[\"population_percent\"] = (\n",
    "        summary[\"population_n\"] / pop_total * 100.0\n",
    "        if pop_total > 0 else 0.0\n",
    "    )\n",
    "    summary[\"sample_percent\"] = (\n",
    "        summary[\"sample_n\"] / samp_total * 100.0\n",
    "        if samp_total > 0 else 0.0\n",
    "    )\n",
    "    summary[\"percent_diff\"] = summary[\"sample_percent\"] - summary[\"population_percent\"]\n",
    "\n",
    "    # Sort by population size (descending), then by FinalFormat for stability\n",
    "    summary = summary.sort_values(\n",
    "        by=[\"population_n\", \"FinalFormat\"],\n",
    "        ascending=[False, True]\n",
    "    ).reset_index(drop=True)\n",
    "\n",
    "    return summary\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 8B. Ensure coverage of all FinalFormats in the sample\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "def enforce_format_coverage(\n",
    "    sample_df: pd.DataFrame,\n",
    "    df_nontrivial: pd.DataFrame,\n",
    "    random_state: int = 42,\n",
    "):\n",
    "    \"\"\"\n",
    "    Ensure that every FinalFormat that appears in the non-trivial universe\n",
    "    also appears at least once in the sample.\n",
    "\n",
    "    If some formats are missing, top up by adding 1 row for each missing format\n",
    "    (without replacement from the universe).\n",
    "\n",
    "    Returns:\n",
    "      sample_with_formats: final sample after top-up\n",
    "      added_rows: DataFrame of rows added by the coverage step (can be empty)\n",
    "      missing_formats: list[str] of formats that were missing before top-up\n",
    "    \"\"\"\n",
    "    sample = sample_df.copy()\n",
    "\n",
    "    universe_formats = (\n",
    "        df_nontrivial[\"FinalFormat\"]\n",
    "        .dropna()\n",
    "        .astype(str)\n",
    "        .unique()\n",
    "        .tolist()\n",
    "    )\n",
    "\n",
    "    present_counts = (\n",
    "        sample[\"FinalFormat\"]\n",
    "        .dropna()\n",
    "        .astype(str)\n",
    "        .value_counts()\n",
    "    )\n",
    "\n",
    "    missing_formats = [fmt for fmt in universe_formats if present_counts.get(fmt, 0) == 0]\n",
    "\n",
    "    added_rows_list = []\n",
    "    for fmt in missing_formats:\n",
    "        candidates = df_nontrivial[df_nontrivial[\"FinalFormat\"].astype(str) == fmt]\n",
    "        candidates = candidates.loc[~candidates.index.isin(sample.index)]  # avoid duplicates\n",
    "        if len(candidates) > 0:\n",
    "            extra = candidates.sample(n=1, random_state=random_state)\n",
    "            added_rows_list.append(extra)\n",
    "\n",
    "    if added_rows_list:\n",
    "        added_rows = pd.concat(added_rows_list)\n",
    "        sample = pd.concat([sample, added_rows])\n",
    "    else:\n",
    "        added_rows = pd.DataFrame(columns=sample.columns)\n",
    "\n",
    "    return sample, added_rows, missing_formats\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 9. Main pipeline\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "def main():\n",
    "    input_file = \"AnalysedColumnsKaggleViznetFiltered.xlsx\"\n",
    "    output_file = \"KaggleViznet_95CI_StatAudit_UniverseAndSample.xlsx\"\n",
    "\n",
    "    # 9.1 load data\n",
    "    df = pd.read_excel(input_file)\n",
    "    print(f\"Total rows in file: {len(df)}\")\n",
    "\n",
    "    # 9.2 clean VizNet-style names in 'name'\n",
    "    if \"name\" in df.columns:\n",
    "        df[\"name\"] = df[\"name\"].apply(clean_viznet_name)\n",
    "\n",
    "    # 9.3 restrict to rows with non-null FinalFormat\n",
    "    df_universe = df[df[\"FinalFormat\"].notna()].copy()\n",
    "    print(f\"Universe (FinalFormat not NaN): {len(df_universe)}\")\n",
    "\n",
    "    # 9.4 abbreviation flag\n",
    "    df_universe = compute_abbrev_used(df_universe)\n",
    "\n",
    "    # 9.5 original token stats (includes orig_numeric_only)\n",
    "    df_universe = add_original_token_stats(df_universe)\n",
    "\n",
    "    # 9.6 trivial flag based on CleanedColumn\n",
    "    df_universe = add_trivial_flag(df_universe)\n",
    "\n",
    "    # 9.7 define \"trivial_strict\":\n",
    "    #     - trivial_single_token (CleanedColumn)\n",
    "    #     - AND (orig_single_token OR orig_numeric_only)\n",
    "    #       -> includes pure numeric headers (years, 1991/92, etc)\n",
    "    #          but keeps symbol-only headers (#, %, %+/-) as non-trivial.\n",
    "    df_universe[\"trivial_strict\"] = (\n",
    "        df_universe[\"trivial_single_token\"]\n",
    "        & (df_universe[\"orig_single_token\"] | df_universe[\"orig_numeric_only\"])\n",
    "    )\n",
    "\n",
    "    # 9.8 split strict trivial and non-trivial\n",
    "    df_trivial_strict = df_universe[df_universe[\"trivial_strict\"]].copy()\n",
    "    df_nontrivial = df_universe[~df_universe[\"trivial_strict\"]].copy()\n",
    "\n",
    "    # For information: trivial_single_token but original multi-token\n",
    "    mask_triv_cleaned_orig_multi = (\n",
    "        df_universe[\"trivial_single_token\"]\n",
    "        & (~df_universe[\"orig_single_token\"])\n",
    "        & (~df_universe[\"orig_numeric_only\"])\n",
    "    )\n",
    "    df_trivial_cleaned_orig_multi = df_universe[mask_triv_cleaned_orig_multi].copy()\n",
    "\n",
    "    print(f\"Strict trivial (Cleaned single token + orig word or numeric-only): {len(df_trivial_strict)}\")\n",
    "    print(f\"trivial_single_token but original multi-token (non-trivial): {len(df_trivial_cleaned_orig_multi)}\")\n",
    "    print(f\"Non-trivial rows for sampling: {len(df_nontrivial)}\")\n",
    "\n",
    "    # 9.9 stratified sample on non-trivial rows\n",
    "    sample_df_raw, strata_info = build_stratified_sample_by_area_abbrev(df_nontrivial)\n",
    "    print(f\"Raw stratified sample size (before coverage correction): {len(sample_df_raw)}\")\n",
    "\n",
    "    # 9.10 formats summary before enforcing coverage\n",
    "    formats_summary_before = build_formats_summary(df_nontrivial, sample_df_raw)\n",
    "\n",
    "    # 9.11 enforce FinalFormat coverage\n",
    "    sample_df, added_rows, missing_formats = enforce_format_coverage(sample_df_raw, df_nontrivial)\n",
    "    print(f\"Final sample size (after coverage correction): {len(sample_df)}\")\n",
    "    print(f\"Rows added by coverage correction: {len(added_rows)}\")\n",
    "    if missing_formats:\n",
    "        print(\"Formats added by coverage correction:\")\n",
    "        print(\", \".join(missing_formats))\n",
    "\n",
    "    # 9.12 formats summary after enforcing coverage\n",
    "    formats_summary_after = build_formats_summary(df_nontrivial, sample_df)\n",
    "\n",
    "    # 9.13 area summary\n",
    "    area_summary = build_area_summary(df_nontrivial, sample_df)\n",
    "\n",
    "    # 9.14 write outputs to Excel\n",
    "    with pd.ExcelWriter(output_file, engine=\"openpyxl\") as writer:\n",
    "        sample_df.to_excel(writer, sheet_name=\"Nontrivial_Sample\", index=False)\n",
    "        df_nontrivial.to_excel(writer, sheet_name=\"Nontrivial_Universe\", index=False)\n",
    "        df_trivial_strict.to_excel(writer, sheet_name=\"Trivial_Universe\", index=False)\n",
    "        df_trivial_cleaned_orig_multi.to_excel(\n",
    "            writer, sheet_name=\"Trivial_cleaned_orig_multi\", index=False\n",
    "        )\n",
    "        area_summary.to_excel(writer, sheet_name=\"Area_Summary\", index=False)\n",
    "        strata_info.to_excel(writer, sheet_name=\"Strata_Summary\", index=False)\n",
    "\n",
    "        # Updated formats outputs\n",
    "        formats_summary_before.to_excel(writer, sheet_name=\"Formats_Summary_BeforeCoverage\", index=False)\n",
    "        formats_summary_after.to_excel(writer, sheet_name=\"Formats_Summary_AfterCoverage\", index=False)\n",
    "        added_rows.to_excel(writer, sheet_name=\"Formats_Added_ByCoverage\", index=False)\n",
    "\n",
    "    print(f\"\\nResults written to: {output_file}\")\n",
    "\n",
    "    from datetime import datetime\n",
    "    print(f\"Last run on: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "134daa04",
   "metadata": {},
   "source": [
    "Creates GPTAnalysisOn2295.xlsx and GPTOutputsOn2295.xlsx is just a manual copy of the first sheet of KaggleViznet_95CI_StatAudit_UniverseAndSample.xlsx.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c70fa1f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last run on: 2025-12-13 15:32:03\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "def _to_bool(value):\n",
    "    \"\"\"\n",
    "    Robust conversion to boolean for mixed columns like\n",
    "    TRUE/FALSE, 1/0, yes/no, etc.\n",
    "    \"\"\"\n",
    "    if pd.isna(value):\n",
    "        return False\n",
    "    if isinstance(value, (int, float)):\n",
    "        return bool(value)\n",
    "    if isinstance(value, str):\n",
    "        v = value.strip().lower()\n",
    "        return v in {\"true\", \"t\", \"1\", \"yes\", \"y\"}\n",
    "    return bool(value)\n",
    "\n",
    "\n",
    "def analyze_gpt_outputs_to_excel(input_path: str, output_path: str) -> None:\n",
    "    \"\"\"\n",
    "    Load GPTOutputsOn2295.xlsx and write all analyses into a new\n",
    "    Excel workbook with multiple sheets instead of printing.\n",
    "    \"\"\"\n",
    "\n",
    "    # -------------------\n",
    "    # 1. Load data\n",
    "    # -------------------\n",
    "    df = pd.read_excel(input_path)\n",
    "\n",
    "    n_rows = len(df)\n",
    "    n_cols = len(df.columns)\n",
    "\n",
    "    # Convenience flags\n",
    "    df[\"problem\"] = df[\"GPT_approves_format\"] != 1\n",
    "    df[\"wrong_abbrev\"] = df[\"GPT_found_wrong_abbrev_expansions\"].apply(_to_bool)\n",
    "    df[\"notes_nonnull\"] = df[\"GPT_notes\"].notna()\n",
    "\n",
    "    # -------------------\n",
    "    # 2. Global summaries\n",
    "    # -------------------\n",
    "    approves_true = int((df[\"GPT_approves_format\"] == 1).sum())\n",
    "    approves_false = int((df[\"GPT_approves_format\"] == 0).sum())\n",
    "\n",
    "    global_summary = pd.DataFrame(\n",
    "        [\n",
    "            [\"rows_total\", n_rows],\n",
    "            [\"columns_total\", n_cols],\n",
    "            [\"approves_true\", approves_true],\n",
    "            [\"approves_true_rate\", approves_true / n_rows if n_rows else 0],\n",
    "            [\"approves_false\", approves_false],\n",
    "            [\"approves_false_rate\", approves_false / n_rows if n_rows else 0],\n",
    "        ],\n",
    "        columns=[\"metric\", \"value\"],\n",
    "    )\n",
    "\n",
    "    no_finalformat_counts = (\n",
    "        df[\"no_FinalFormat_found\"].value_counts(dropna=False)\n",
    "        .rename_axis(\"no_FinalFormat_found\")\n",
    "        .reset_index(name=\"count\")\n",
    "    )\n",
    "    no_finalformat_counts[\"proportion\"] = (\n",
    "        no_finalformat_counts[\"count\"] / n_rows if n_rows else 0\n",
    "    )\n",
    "\n",
    "    wrong_abbrev_total = int(df[\"wrong_abbrev\"].sum())\n",
    "    wrong_abbrev_summary = pd.DataFrame(\n",
    "        [\n",
    "            [\"wrong_abbrev_true\", wrong_abbrev_total],\n",
    "            [\n",
    "                \"wrong_abbrev_rate\",\n",
    "                wrong_abbrev_total / n_rows if n_rows else 0,\n",
    "            ],\n",
    "        ],\n",
    "        columns=[\"metric\", \"value\"],\n",
    "    )\n",
    "\n",
    "    # -------------------\n",
    "    # 3. FinalFormat distribution and problems\n",
    "    # -------------------\n",
    "    ff_counts = df[\"FinalFormat\"].value_counts().sort_values(ascending=False)\n",
    "    ff_table = ff_counts.to_frame(\"count\")\n",
    "    ff_table[\"proportion\"] = ff_table[\"count\"] / n_rows if n_rows else 0\n",
    "    ff_table = ff_table.reset_index().rename(columns={\"index\": \"FinalFormat\"})\n",
    "\n",
    "    problem_df = df[df[\"problem\"]]\n",
    "    total_per_ff = df.groupby(\"FinalFormat\").size()\n",
    "    problems_per_ff = problem_df.groupby(\"FinalFormat\").size()\n",
    "\n",
    "    problem_stats = (\n",
    "        pd.DataFrame({\"total\": total_per_ff, \"problems\": problems_per_ff})\n",
    "        .fillna(0)\n",
    "        .astype({\"problems\": \"int\"})\n",
    "    )\n",
    "    problem_stats[\"problem_rate\"] = (\n",
    "        problem_stats[\"problems\"] / problem_stats[\"total\"]\n",
    "    )\n",
    "    problem_stats = problem_stats.reset_index()\n",
    "\n",
    "    # -------------------\n",
    "    # 4. Format transitions (for problem cases only)\n",
    "    # -------------------\n",
    "    if not problem_df.empty:\n",
    "        fmt_sugg = (\n",
    "            problem_df.groupby(\n",
    "                [\"FinalFormat\", \"GPT_suggested_correct_format\"]\n",
    "            )\n",
    "            .size()\n",
    "            .reset_index(name=\"count\")\n",
    "            .sort_values(\"count\", ascending=False)\n",
    "        )\n",
    "    else:\n",
    "        fmt_sugg = pd.DataFrame(\n",
    "            columns=[\"FinalFormat\", \"GPT_suggested_correct_format\", \"count\"]\n",
    "        )\n",
    "\n",
    "    # -------------------\n",
    "    # 5. Keyword suggestions\n",
    "    # -------------------\n",
    "    kw_df = df[df[\"GPT_suggested_correct_keyword\"].notna()]\n",
    "    if not kw_df.empty:\n",
    "        kw_pairs = (\n",
    "            kw_df.groupby([\"SourceKeyword\", \"GPT_suggested_correct_keyword\"])\n",
    "            .size()\n",
    "            .reset_index(name=\"count\")\n",
    "            .sort_values(\"count\", ascending=False)\n",
    "        )\n",
    "    else:\n",
    "        kw_pairs = pd.DataFrame(\n",
    "            columns=[\"SourceKeyword\", \"GPT_suggested_correct_keyword\", \"count\"]\n",
    "        )\n",
    "\n",
    "    # -------------------\n",
    "    # 6. Abbreviation impact\n",
    "    # -------------------\n",
    "    abbrev_group = df.groupby(\"abbrev_used\")[\"problem\"].agg(\n",
    "        total=\"size\", problems=\"sum\"\n",
    "    )\n",
    "    abbrev_group[\"problem_rate\"] = (\n",
    "        abbrev_group[\"problems\"] / abbrev_group[\"total\"]\n",
    "    )\n",
    "    abbrev_group = abbrev_group.reset_index()\n",
    "\n",
    "    wrong_abbrev_by_area = df.groupby(\"area\")[\"wrong_abbrev\"].sum()\n",
    "    total_by_area = df.groupby(\"area\").size()\n",
    "    abbrev_area = (\n",
    "        pd.DataFrame(\n",
    "            {\"total\": total_by_area, \"wrong_abbrev\": wrong_abbrev_by_area}\n",
    "        )\n",
    "        .fillna(0)\n",
    "        .astype({\"wrong_abbrev\": \"int\"})\n",
    "    )\n",
    "    abbrev_area[\"wrong_abbrev_rate\"] = (\n",
    "        abbrev_area[\"wrong_abbrev\"] / abbrev_area[\"total\"]\n",
    "    )\n",
    "    abbrev_area = abbrev_area.reset_index()\n",
    "\n",
    "    # -------------------\n",
    "    # 7. Problems by area\n",
    "    # -------------------\n",
    "    problems_per_area = problem_df.groupby(\"area\").size()\n",
    "    area_stats = (\n",
    "        pd.DataFrame(\n",
    "            {\"total\": total_by_area, \"problems\": problems_per_area}\n",
    "        )\n",
    "        .fillna(0)\n",
    "        .astype({\"problems\": \"int\"})\n",
    "    )\n",
    "    area_stats[\"problem_rate\"] = (\n",
    "        area_stats[\"problems\"] / area_stats[\"total\"]\n",
    "    )\n",
    "    area_stats = area_stats.reset_index()\n",
    "\n",
    "    # -------------------\n",
    "    # 8. GPT_notes coverage\n",
    "    # -------------------\n",
    "    notes_nonnull = int(df[\"notes_nonnull\"].sum())\n",
    "    notes_summary = pd.DataFrame(\n",
    "        [\n",
    "            [\"rows_with_notes\", notes_nonnull],\n",
    "            [\n",
    "                \"notes_coverage_rate\",\n",
    "                notes_nonnull / n_rows if n_rows else 0,\n",
    "            ],\n",
    "        ],\n",
    "        columns=[\"metric\", \"value\"],\n",
    "    )\n",
    "\n",
    "    notes_ff = (\n",
    "        df.groupby(\"FinalFormat\")[\"notes_nonnull\"]\n",
    "        .mean()\n",
    "        .rename(\"notes_coverage_rate\")\n",
    "        .reset_index()\n",
    "        .sort_values(\"notes_coverage_rate\", ascending=False)\n",
    "    )\n",
    "\n",
    "    notes_area = (\n",
    "        df.groupby(\"area\")[\"notes_nonnull\"]\n",
    "        .mean()\n",
    "        .rename(\"notes_coverage_rate\")\n",
    "        .reset_index()\n",
    "        .sort_values(\"notes_coverage_rate\", ascending=False)\n",
    "    )\n",
    "\n",
    "    # -------------------\n",
    "    # 9. Write everything to Excel\n",
    "    # -------------------\n",
    "    # Let pandas choose the engine (usually openpyxl), so we do not need xlsxwriter.\n",
    "    with pd.ExcelWriter(output_path) as writer:\n",
    "        # Global sheet\n",
    "        global_summary.to_excel(\n",
    "            writer, sheet_name=\"GlobalSummary\", index=False\n",
    "        )\n",
    "        no_finalformat_counts.to_excel(\n",
    "            writer, sheet_name=\"GlobalSummary\", index=False, startrow=8\n",
    "        )\n",
    "        wrong_abbrev_summary.to_excel(\n",
    "            writer,\n",
    "            sheet_name=\"GlobalSummary\",\n",
    "            index=False,\n",
    "            startrow=8 + len(no_finalformat_counts) + 3,\n",
    "        )\n",
    "\n",
    "        # FinalFormat-related\n",
    "        ff_table.to_excel(\n",
    "            writer, sheet_name=\"FinalFormatDistribution\", index=False\n",
    "        )\n",
    "        problem_stats.to_excel(\n",
    "            writer, sheet_name=\"ProblemsByFinalFormat\", index=False\n",
    "        )\n",
    "        fmt_sugg.to_excel(\n",
    "            writer, sheet_name=\"FormatTransitions\", index=False\n",
    "        )\n",
    "        kw_pairs.to_excel(\n",
    "            writer, sheet_name=\"KeywordSuggestions\", index=False\n",
    "        )\n",
    "\n",
    "        # Abbreviation impact\n",
    "        abbrev_group.to_excel(\n",
    "            writer, sheet_name=\"AbbrevGlobal\", index=False\n",
    "        )\n",
    "        abbrev_area.to_excel(\n",
    "            writer, sheet_name=\"AbbrevByArea\", index=False\n",
    "        )\n",
    "\n",
    "        # Area stats\n",
    "        area_stats.to_excel(\n",
    "            writer, sheet_name=\"ProblemsByArea\", index=False\n",
    "        )\n",
    "\n",
    "        # Notes coverage\n",
    "        notes_summary.to_excel(\n",
    "            writer, sheet_name=\"NotesSummary\", index=False\n",
    "        )\n",
    "        notes_ff.to_excel(\n",
    "            writer, sheet_name=\"NotesByFinalFormat\", index=False\n",
    "        )\n",
    "        notes_area.to_excel(\n",
    "            writer, sheet_name=\"NotesByArea\", index=False\n",
    "        )\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_path = \"GPTOutputsOn2295.xlsx\"\n",
    "    output_path = \"GPTAnalysisOn2295.xlsx\"\n",
    "    analyze_gpt_outputs_to_excel(input_path, output_path)\n",
    "\n",
    "    from datetime import datetime\n",
    "    print(f\"Last run on: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf26af70",
   "metadata": {},
   "source": [
    "full 795 items with the 11 problematic expansions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0f99a3c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading superset from: AnalysedColumnsKaggleViznetFiltered.xlsx\n",
      "Total rows in superset: 118639\n",
      "Rows with at least one suspicious abbreviation: 795\n",
      "Filtered rows written to: K_V_superset_suspicious_abbrev.xlsx\n",
      "Last run on: 2025-12-14 14:24:13\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "def extract_suspicious_abbrev_rows(\n",
    "    superset_path: str,\n",
    "    output_path: str = \"K_V_superset_suspicious_abbrev.xlsx\"\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Extract all rows from the Kaggle+VizNet superset that contain any of a given\n",
    "    set of suspicious abbreviation expansions in one of the abbreviation columns.\n",
    "\n",
    "    It searches the following columns:\n",
    "      - abbrev_clean\n",
    "      - abbrev_desc\n",
    "      - abbrev_clean_analysis\n",
    "\n",
    "    And filters rows where at least one of these columns contains one of the\n",
    "    suspicious expansions.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    superset_path : str\n",
    "        Path to the full K+V superset file (118k headers) with abbreviation columns.\n",
    "    output_path : str, optional\n",
    "        Path of the Excel file that will contain the filtered rows.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        DataFrame with all matching rows, including a helper column\n",
    "        'suspicious_abbrev_hits' listing which abbrev(s) were found.\n",
    "    \"\"\"\n",
    "    # 1. Suspicious expansions to trace\n",
    "    suspicious_expansions = [\n",
    "        \"e->errors\",\n",
    "        \"hr->heart rate\",\n",
    "        \"ip->internet protocol\",\n",
    "        \"co->carbon oxide\",\n",
    "        \"int->interception\",\n",
    "        \"sl->soil\",\n",
    "        \"acc->accuracy\",\n",
    "        \"cmp->completions\",\n",
    "        \"direct->direction\",\n",
    "        \"uk->unique key\",\n",
    "        \"reg->region\",\n",
    "    ]\n",
    "\n",
    "    # 2. Columns that may contain abbreviation expansions\n",
    "    abbrev_cols = [\"abbrev_clean\", \"abbrev_desc\", \"abbrev_clean_analysis\"]\n",
    "\n",
    "    print(f\"Loading superset from: {superset_path}\")\n",
    "    df = pd.read_excel(superset_path)\n",
    "\n",
    "    # 3. Sanity check: all required columns must exist\n",
    "    missing = [c for c in abbrev_cols if c not in df.columns]\n",
    "    if missing:\n",
    "        raise ValueError(\n",
    "            f\"The following required columns are missing in the superset file: {missing}\"\n",
    "        )\n",
    "\n",
    "    # 4. Build mask of rows that contain at least one suspicious expansion\n",
    "    mask_any = None\n",
    "    for col in abbrev_cols:\n",
    "        col_mask = df[col].isin(suspicious_expansions)\n",
    "        mask_any = col_mask if mask_any is None else (mask_any | col_mask)\n",
    "\n",
    "    # If no rows match, bail out gracefully\n",
    "    if mask_any is None:\n",
    "        print(\"No abbreviation columns processed. Check the column list.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    matched = df[mask_any].copy()\n",
    "\n",
    "    # 5. Build a helper column listing which expansions were hit and where\n",
    "    def collect_hits(row) -> str:\n",
    "        hits = []\n",
    "        for col in abbrev_cols:\n",
    "            val = row[col]\n",
    "            if isinstance(val, str) and val in suspicious_expansions:\n",
    "                hits.append(f\"{col}:{val}\")\n",
    "        return \"; \".join(hits)\n",
    "\n",
    "    matched[\"suspicious_abbrev_hits\"] = matched.apply(collect_hits, axis=1)\n",
    "\n",
    "    # 6. Report basic stats\n",
    "    print(f\"Total rows in superset: {len(df)}\")\n",
    "    print(f\"Rows with at least one suspicious abbreviation: {len(matched)}\")\n",
    "\n",
    "    # 7. Write to Excel (single sheet)\n",
    "    matched.to_excel(output_path, index=False)\n",
    "    print(f\"Filtered rows written to: {output_path}\")\n",
    "\n",
    "    return matched\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # TODO: update this path to your real 118k+V superset file\n",
    "    superset_file = r\"AnalysedColumnsKaggleViznetFiltered.xlsx\"\n",
    "\n",
    "    output_file = \"K_V_superset_suspicious_abbrev.xlsx\"\n",
    "\n",
    "    result_df = extract_suspicious_abbrev_rows(\n",
    "        superset_path=superset_file,\n",
    "        output_path=output_file,\n",
    "    )\n",
    "\n",
    "    print(f\"Last run on: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b72db934",
   "metadata": {},
   "source": [
    "Analysing 795 for correctness of abbreviations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301a1e44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision counts per abbreviation (only part after ':'):\n",
      "GPT_abbrev_decision                 abbrev  OK  UNCERTAIN  WRONG_ABBREV  total\n",
      "0                            acc->accuracy  20          4            15     39\n",
      "1                         cmp->completions  14          0            16     30\n",
      "2                         co->carbon oxide  20          2            51     73\n",
      "3                        direct->direction   0          0            27     27\n",
      "4                                e->errors  35          8           128    171\n",
      "5                           hr->heart rate   2          1           159    162\n",
      "6                        int->interception  48          0            19     67\n",
      "7                    ip->internet protocol  49          4            81    134\n",
      "8                              reg->region   0          5            11     16\n",
      "9                                 sl->soil   0          0            56     56\n",
      "10                          uk->unique key   0          0            20     20\n",
      "\n",
      "Suggested expansions per abbreviation (only part after ':'):\n",
      "             abbrev                 GPT_suggested_abbrev  count\n",
      "0     acc->accuracy                                          20\n",
      "1     acc->accuracy                      acc -> accounts      6\n",
      "2     acc->accuracy                   acc -> accumulated      5\n",
      "3     acc->accuracy  acc -> accelerometer / acceleration      2\n",
      "4     acc->accuracy      acc -> accuracy (needs context)      2\n",
      "..              ...                                  ...    ...\n",
      "170  uk->unique key                   UK->United Kingdom      8\n",
      "171  uk->unique key       UK->United Kingdom (shoe size)      7\n",
      "172  uk->unique key  UK->United Kingdom (chart position)      3\n",
      "173  uk->unique key          UK->United Kingdom (market)      1\n",
      "174  uk->unique key            UK->United Kingdom (size)      1\n",
      "\n",
      "[175 rows x 3 columns]\n",
      "\n",
      "Summaries written to: abbrev_review_summary.xlsx\n",
      "Last run on: 2025-12-14 20:21:25\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "def load_abbrev_review_excel(\n",
    "    file_path: str,\n",
    "    sheet_name: str | int | None = 0\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load the suspicious abbreviation review Excel file into a pandas DataFrame.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    file_path : str\n",
    "        Path to the Excel file, for example:\n",
    "        'K_V_superset_suspicious_abbrev.xlsx'.\n",
    "    sheet_name : str or int or None, optional\n",
    "        Sheet name or index to read. Default is 0 (first sheet).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        DataFrame with all columns from the Excel sheet.\n",
    "    \"\"\"\n",
    "    df = pd.read_excel(file_path, sheet_name=sheet_name)\n",
    "    return df\n",
    "\n",
    "\n",
    "def normalise_abbrev_values(series: pd.Series) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Take a Series with values like 'abbrev_clean:ip->internet protocol'\n",
    "    or 'abbrev_desc:e->errors' and return only the part after the colon,\n",
    "    for example 'ip->internet protocol' or 'e->errors'.\n",
    "\n",
    "    If there is no colon, returns the stripped original value.\n",
    "    \"\"\"\n",
    "    s = series.fillna(\"\").astype(str)\n",
    "    # Split only once, keep the last part so:\n",
    "    # 'abbrev_clean:ip->internet protocol' -> ['abbrev_clean', 'ip->internet protocol'] -> take index -1\n",
    "    s = s.str.split(\":\", n=1).str[-1].str.strip()\n",
    "    return s\n",
    "\n",
    "\n",
    "def summarise_decisions_per_abbrev(\n",
    "    df: pd.DataFrame,\n",
    "    abbrev_col: str = \"suspicious_abbrev_hits\",\n",
    "    decision_col: str = \"GPT_abbrev_decision\"\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    For each suspicious abbreviation, count how many times it received\n",
    "    each GPT_abbrev_decision value (OK, WRONG_ABBREV, UNCERTAIN).\n",
    "\n",
    "    The abbreviation values are normalised to keep only what is after ':'.\n",
    "    For example:\n",
    "        'abbrev_clean:ip->internet protocol'\n",
    "    becomes:\n",
    "        'ip->internet protocol'\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        Input DataFrame containing at least abbrev_col and decision_col.\n",
    "    abbrev_col : str\n",
    "        Column name with the raw abbreviation pattern.\n",
    "    decision_col : str\n",
    "        Column name with the GPT decision.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        A pivot table with one row per normalised abbreviation and one column\n",
    "        per decision.\n",
    "        Example columns: ['abbrev', 'OK', 'WRONG_ABBREV', 'UNCERTAIN', 'total'].\n",
    "    \"\"\"\n",
    "    temp_df = df.copy()\n",
    "    # Create a cleaned abbreviation column that only keeps what is after ':'\n",
    "    temp_df[\"abbrev\"] = normalise_abbrev_values(temp_df[abbrev_col])\n",
    "\n",
    "    pivot = (\n",
    "        temp_df\n",
    "        .pivot_table(\n",
    "            index=\"abbrev\",\n",
    "            columns=decision_col,\n",
    "            aggfunc=\"size\",\n",
    "            fill_value=0\n",
    "        )\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    for col in [\"OK\", \"WRONG_ABBREV\", \"UNCERTAIN\"]:\n",
    "        if col not in pivot.columns:\n",
    "            pivot[col] = 0\n",
    "\n",
    "    decision_cols = [c for c in pivot.columns if c in [\"OK\", \"WRONG_ABBREV\", \"UNCERTAIN\"]]\n",
    "    pivot[\"total\"] = pivot[decision_cols].sum(axis=1)\n",
    "\n",
    "    pivot = pivot.sort_values(by=\"abbrev\").reset_index(drop=True)\n",
    "    return pivot\n",
    "\n",
    "\n",
    "def summarise_suggested_expansions(\n",
    "    df: pd.DataFrame,\n",
    "    abbrev_col: str = \"suspicious_abbrev_hits\",\n",
    "    suggested_col: str = \"GPT_suggested_abbrev\"\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    For each suspicious abbreviation, count how many times each\n",
    "    GPT_suggested_abbrev string appears.\n",
    "\n",
    "    The abbreviation values are normalised to keep only what is after ':'.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        Input DataFrame containing at least abbrev_col and suggested_col.\n",
    "    abbrev_col : str\n",
    "        Column name with the raw abbreviation pattern.\n",
    "    suggested_col : str\n",
    "        Column name with GPT suggested expansion.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        DataFrame with columns:\n",
    "        ['abbrev', suggested_col, 'count'], sorted for readability.\n",
    "    \"\"\"\n",
    "    temp_df = df.copy()\n",
    "    temp_df[\"abbrev\"] = normalise_abbrev_values(temp_df[abbrev_col])\n",
    "    temp_df[suggested_col] = temp_df[suggested_col].fillna(\"\").astype(str).str.strip()\n",
    "\n",
    "    grouped = (\n",
    "        temp_df\n",
    "        .groupby([\"abbrev\", suggested_col], dropna=False)\n",
    "        .size()\n",
    "        .reset_index(name=\"count\")\n",
    "    )\n",
    "\n",
    "    grouped = grouped.sort_values(\n",
    "        by=[\"abbrev\", \"count\", suggested_col],\n",
    "        ascending=[True, False, True]\n",
    "    ).reset_index(drop=True)\n",
    "\n",
    "    return grouped\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Example usage:\n",
    "    - Load your Excel file.\n",
    "    - Compute decision counts per normalised abbreviation.\n",
    "    - Compute suggested expansion counts per normalised abbreviation.\n",
    "    - Print and optionally write to Excel.\n",
    "    \"\"\"\n",
    "    input_file = \"K_V_superset_suspicious_abbrev.xlsx\"\n",
    "\n",
    "    abbrev_col_name = \"suspicious_abbrev_hits\"\n",
    "    decision_col_name = \"GPT_abbrev_decision\"\n",
    "    suggested_col_name = \"GPT_suggested_abbrev\"\n",
    "\n",
    "    df = load_abbrev_review_excel(input_file)\n",
    "\n",
    "    decision_summary = summarise_decisions_per_abbrev(\n",
    "        df,\n",
    "        abbrev_col=abbrev_col_name,\n",
    "        decision_col=decision_col_name\n",
    "    )\n",
    "\n",
    "    suggested_summary = summarise_suggested_expansions(\n",
    "        df,\n",
    "        abbrev_col=abbrev_col_name,\n",
    "        suggested_col=suggested_col_name\n",
    "    )\n",
    "\n",
    "    print(\"Decision counts per abbreviation (only part after ':'):\")\n",
    "    print(decision_summary)\n",
    "\n",
    "    print(\"\\nSuggested expansions per abbreviation (only part after ':'):\")\n",
    "    print(suggested_summary)\n",
    "\n",
    "    output_file = \"abbrev_review_summary.xlsx\"\n",
    "\n",
    "    try:\n",
    "        with pd.ExcelWriter(output_file) as writer:\n",
    "            decision_summary.to_excel(writer, sheet_name=\"decision_counts\", index=False)\n",
    "            suggested_summary.to_excel(writer, sheet_name=\"suggested_counts\", index=False)\n",
    "        print(f\"\\nSummaries written to: {output_file}\")\n",
    "    except ModuleNotFoundError as e:\n",
    "        print(\"\\nCould not write Excel file because an engine is missing.\")\n",
    "        print(f\"Details: {e}\")\n",
    "        print(\"The printed tables above are still correct. \"\n",
    "              \"To generate Excel output, install an engine such as 'openpyxl' or 'xlsxwriter'.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n",
    "print(f\"Last run on: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
